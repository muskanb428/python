{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e67ebd4-c938-4030-96cf-ffc5e28bf7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nglview in c:\\users\\muska\\anaconda3\\lib\\site-packages (4.0)\n",
      "Requirement already satisfied: ipywidgets>=8 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nglview) (8.1.5)\n",
      "Requirement already satisfied: notebook>=7 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nglview) (7.3.2)\n",
      "Requirement already satisfied: jupyterlab>=3 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nglview) (4.3.4)\n",
      "Requirement already satisfied: jupyterlab_widgets in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nglview) (3.0.13)\n",
      "Requirement already satisfied: numpy<2.3 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nglview) (2.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipywidgets>=8->nglview) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipywidgets>=8->nglview) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipywidgets>=8->nglview) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipywidgets>=8->nglview) (4.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (2.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8->nglview) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\muska\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=8->nglview) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8->nglview) (0.8.4)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (0.28.1)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (6.29.5)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (3.1.6)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (2.2.5)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (2.15.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (2.27.3)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (0.2.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (24.2)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (72.1.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab>=3->nglview) (6.5.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (4.7.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (21.3.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (8.6.3)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (7.16.6)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (5.10.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.21.1)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (2.0.15)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (26.2.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.8.0)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (0.9.25)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (4.23.0)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\muska\\anaconda3\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (21.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\muska\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab>=3->nglview) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\muska\\anaconda3\\lib\\site-packages (from httpx>=0.25.0->jupyterlab>=3->nglview) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab>=3->nglview) (0.16.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab>=3->nglview) (1.8.11)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab>=3->nglview) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\muska\\anaconda3\\lib\\site-packages (from ipykernel>=6.5.0->jupyterlab>=3->nglview) (5.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jinja2>=3.0.3->jupyterlab>=3->nglview) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (0.22.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-core->jupyterlab>=3->nglview) (4.3.7)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-core->jupyterlab>=3->nglview) (308)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (3.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.1.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (2.1)\n",
      "Requirement already satisfied: uri-template in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (25.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (3.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\muska\\anaconda3\\lib\\site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (2.20.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab>=3->nglview) (2.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\muska\\anaconda3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (2.21)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (2.5)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=3->nglview) (1.3.0)\n",
      "Requirement already satisfied: executing in c:\\users\\muska\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8->nglview) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\muska\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8->nglview) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\muska\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=8->nglview) (0.2.2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c538134e3ec4da5822bb11c10d9aa50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'nglview' has no attribute 'enable_notebook'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install nglview\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnglview\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnv\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m nv\u001b[38;5;241m.\u001b[39menable_notebook()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnglview\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnv\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnglview version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, nv\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'nglview' has no attribute 'enable_notebook'"
     ]
    }
   ],
   "source": [
    "!pip install nglview\n",
    "import nglview as nv\n",
    "nv.enable_notebook()\n",
    "import nglview as nv\n",
    "print(\"nglview version:\", nv.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e12f43-4b44-4392-8f9f-b7bd09003af9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¬ Pathogenic residues found: [186. 194. 201. 215. 268.   2.  10.  31.  17.  84.]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "148ac843dabe465eacda15cc9d6021b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nglview as nv\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "# --- Step 1: Load your data ---\n",
    "df = pd.read_csv(r\"E:\\vit\\ai\\data\\BDNF_missense_expanded_mapped.csv\")\n",
    "\n",
    "# --- Step 2: Filter pathogenic variants (case-insensitive) ---\n",
    "pathogenic_positions = df.loc[\n",
    "    df[\"Germline classification\"].str.lower().str.contains(\"pathogenic\", na=False),\n",
    "    \"Residue\"\n",
    "].dropna().unique()\n",
    "\n",
    "print(\"ðŸ§¬ Pathogenic residues found:\", pathogenic_positions)\n",
    "\n",
    "# --- Step 3: Load the structure (update path if needed) ---\n",
    "pdb_path = r\"E:\\vit\\ai\\8OYD.pdb\"  # replace with your actual local path\n",
    "parser = PDBParser(QUIET=True)\n",
    "structure = parser.get_structure(\"BDNF\", pdb_path)\n",
    "\n",
    "# --- Step 4: Visualize in nglview ---\n",
    "view = nv.show_biopython(structure)\n",
    "view.add_cartoon(color=\"grey\")\n",
    "\n",
    "# --- Step 5: Highlight pathogenic residues in red ---\n",
    "for res_num in pathogenic_positions:\n",
    "    try:\n",
    "        selection = f\"{int(res_num)}\"\n",
    "        view.add_representation(\"ball+stick\", selection=selection, color=\"red\")\n",
    "    except ValueError:\n",
    "        pass  # ignore any non-numeric residues\n",
    "\n",
    "# --- Step 6: Display ---\n",
    "view.center()\n",
    "view\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2207fc0e-d1b1-4f50-b855-e6cb9a19c06e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Gene(s)', 'Protein change', 'Condition(s)', 'Accession', 'GRCh37Chromosome', 'GRCh37Location', 'GRCh38Chromosome', 'GRCh38Location', 'VariationID', 'AlleleID(s)', 'dbSNP ID', 'Canonical SPDI', 'Variant type', 'Molecular consequence', 'Germline classification', 'Germline date last evaluated', 'Germline review status', 'Somatic clinical impact', 'Somatic clinical impact date last evaluated', 'Somatic clinical impact review status', 'Oncogenicity classification', 'Oncogenicity date last evaluated', 'Oncogenicity review status', 'VariantType', 'Orig_AA', 'Residue', 'New_AA', 'Parsed', 'Region', 'Mature_pos', 'Mapping', 'Truncation_length']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"E:\\vit\\ai\\data\\BDNF_missense_expanded_mapped.csv\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d64d80-519d-4f39-b252-482a216aee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¬ Total pathogenic variants found: 10\n",
      "                       Protein change  Residue\n",
      "30  C186Y, C194Y, C201Y, C215Y, C268Y    186.0\n",
      "31  C186Y, C194Y, C201Y, C215Y, C268Y    194.0\n",
      "32  C186Y, C194Y, C201Y, C215Y, C268Y    201.0\n",
      "33  C186Y, C194Y, C201Y, C215Y, C268Y    215.0\n",
      "34  C186Y, C194Y, C201Y, C215Y, C268Y    268.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14b2ef6f0104473b53fd10bbb476d59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nglview as nv\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "# --- Step 1: Load your variant data ---\n",
    "df = pd.read_csv(r\"E:\\vit\\ai\\data\\BDNF_missense_expanded_mapped.csv\")\n",
    "\n",
    "# --- Step 2: Filter pathogenic variants ---\n",
    "pathogenic_df = df.loc[\n",
    "    df[\"Germline classification\"].str.lower().str.contains(\"pathogenic\", na=False),\n",
    "    [\"Orig_AA\", \"Residue\", \"New_AA\", \"Protein change\"]\n",
    "].dropna()\n",
    "\n",
    "print(\"ðŸ§¬ Total pathogenic variants found:\", len(pathogenic_df))\n",
    "print(pathogenic_df[[\"Protein change\", \"Residue\"]].head())\n",
    "\n",
    "# --- Step 3: Load the structure ---\n",
    "pdb_path = r\"E:\\vit\\ai\\8OYD.pdb\"  # update if necessary\n",
    "parser = PDBParser(QUIET=True)\n",
    "structure = parser.get_structure(\"BDNF\", pdb_path)\n",
    "\n",
    "# --- Step 4: Create NGLView viewer ---\n",
    "view = nv.show_biopython(structure)\n",
    "view.add_cartoon(color=\"grey\")\n",
    "\n",
    "# --- Step 5: Highlight each pathogenic residue and add label ---\n",
    "for _, row in pathogenic_df.iterrows():\n",
    "    try:\n",
    "        res_num = int(row[\"Residue\"])\n",
    "        label = f\"{row['Orig_AA']}{res_num}{row['New_AA']}\"\n",
    "        selection = f\"{res_num}\"\n",
    "        # Highlight residue\n",
    "        view.add_representation(\"ball+stick\", selection=selection, color=\"red\")\n",
    "        # Add label text in 3D\n",
    "        view.shape.add_text(\n",
    "            [0, 0, 0],  # dummy coordinates, replaced below dynamically\n",
    "            label,\n",
    "            color=\"red\",\n",
    "            size=1.0\n",
    "        )\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# --- Step 6: Display viewer ---\n",
    "view.center()\n",
    "view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaa79c28-8b51-4e40-b9de-24f81d56466a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cdd26377354bf5ba2add6c29e344c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nglview as nv\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "# --- Step 1: Load your variant dataset ---\n",
    "df = pd.read_csv(r\"E:\\vit\\ai\\data\\BDNF_missense_expanded_mapped.csv\")\n",
    "\n",
    "# --- Step 2: Keep only relevant columns ---\n",
    "variant_df = df[[\"Germline classification\", \"Orig_AA\", \"Residue\", \"New_AA\", \"Protein change\"]].dropna()\n",
    "\n",
    "# --- Step 3: Define color map for classification ---\n",
    "color_map = {\n",
    "    \"pathogenic\": \"red\",\n",
    "    \"likely pathogenic\": \"orange\",\n",
    "    \"benign\": \"green\",\n",
    "    \"likely benign\": \"lime\",\n",
    "    \"uncertain\": \"yellow\"\n",
    "}\n",
    "\n",
    "# --- Step 4: Load your PDB structure ---\n",
    "pdb_path = r\"E:\\vit\\ai\\8OYD.pdb\"  # update if needed\n",
    "parser = PDBParser(QUIET=True)\n",
    "structure = parser.get_structure(\"BDNF\", pdb_path)\n",
    "\n",
    "# --- Step 5: Create viewer ---\n",
    "view = nv.show_biopython(structure)\n",
    "view.add_cartoon(color=\"grey\")\n",
    "\n",
    "# --- Step 6: Highlight residues based on classification ---\n",
    "for _, row in variant_df.iterrows():\n",
    "    cls = str(row[\"Germline classification\"]).lower()\n",
    "    res_num = row[\"Residue\"]\n",
    "    label = f\"{row['Orig_AA']}{int(res_num)}{row['New_AA']}\"\n",
    "\n",
    "    # Choose color according to classification\n",
    "    color = next((c for k, c in color_map.items() if k in cls), \"white\")\n",
    "\n",
    "    try:\n",
    "        # Highlight the residue\n",
    "        view.add_representation(\"ball+stick\", selection=f\"{int(res_num)}\", color=color)\n",
    "        # Add mutation label\n",
    "        view.shape.add_text(\n",
    "            [0, 0, 0],  # placeholder, text floats near residue\n",
    "            label,\n",
    "            color=color,\n",
    "            size=1.0\n",
    "        )\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# --- Step 7: Show the 3D viewer ---\n",
    "view.center()\n",
    "view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddb8e434-0c7f-47be-8639-7599dbf8f5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4df0f46a6f8472589ac1e7c2753a480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nglview as nv\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "# --- Step 1: Load data ---\n",
    "df = pd.read_csv(r\"E:\\vit\\ai\\data\\BDNF_missense_expanded_mapped.csv\")\n",
    "\n",
    "# --- Step 2: Keep relevant info ---\n",
    "variant_df = df[[\n",
    "    \"Protein change\", \"Residue\", \"Orig_AA\", \"New_AA\",\n",
    "    \"Germline classification\", \"dbSNP ID\", \"Molecular consequence\"\n",
    "]].dropna()\n",
    "\n",
    "# --- Step 3: Define color map ---\n",
    "color_map = {\n",
    "    \"pathogenic\": \"red\",\n",
    "    \"likely pathogenic\": \"orange\",\n",
    "    \"benign\": \"green\",\n",
    "    \"likely benign\": \"lime\",\n",
    "    \"uncertain\": \"yellow\"\n",
    "}\n",
    "\n",
    "# --- Step 4: Load PDB structure ---\n",
    "pdb_path = r\"E:\\vit\\ai\\8OYD.pdb\"\n",
    "parser = PDBParser(QUIET=True)\n",
    "structure = parser.get_structure(\"BDNF\", pdb_path)\n",
    "\n",
    "# --- Step 5: Create NGLView viewer ---\n",
    "view = nv.show_biopython(structure)\n",
    "view.add_cartoon(color=\"grey\")\n",
    "\n",
    "# --- Step 6: Highlight and label residues ---\n",
    "for _, row in variant_df.iterrows():\n",
    "    cls = str(row[\"Germline classification\"]).lower()\n",
    "    res_num = int(row[\"Residue\"])\n",
    "    label = f\"{row['Orig_AA']}{res_num}{row['New_AA']}\"\n",
    "    color = next((c for k, c in color_map.items() if k in cls), \"white\")\n",
    "\n",
    "    # Highlight the residue\n",
    "    view.add_representation(\"ball+stick\", selection=f\"{res_num}\", color=color)\n",
    "\n",
    "# --- Step 7: Define click event handler (displays variant details) ---\n",
    "js_code = \"\"\"\n",
    "this.stage.signals.clicked.add(function(pickingProxy) {\n",
    "    if (pickingProxy && pickingProxy.atom) {\n",
    "        const atom = pickingProxy.atom;\n",
    "        const resno = atom.resno;\n",
    "        const info = window.variantInfo[resno];\n",
    "        if (info) {\n",
    "            alert(\n",
    "                'Residue: ' + resno + '\\\\n' +\n",
    "                'Mutation: ' + info.mutation + '\\\\n' +\n",
    "                'Classification: ' + info.classification + '\\\\n' +\n",
    "                'dbSNP: ' + info.dbsnp + '\\\\n' +\n",
    "                'Consequence: ' + info.consequence\n",
    "            );\n",
    "        }\n",
    "    }\n",
    "});\n",
    "\"\"\"\n",
    "\n",
    "# --- Step 8: Prepare info mapping for JS ---\n",
    "variant_info = {}\n",
    "for _, row in variant_df.iterrows():\n",
    "    try:\n",
    "        res = int(row[\"Residue\"])\n",
    "        variant_info[res] = {\n",
    "            \"mutation\": f\"{row['Orig_AA']}{res}{row['New_AA']}\",\n",
    "            \"classification\": row[\"Germline classification\"],\n",
    "            \"dbsnp\": row.get(\"dbSNP ID\", \"N/A\"),\n",
    "            \"consequence\": row.get(\"Molecular consequence\", \"N/A\")\n",
    "        }\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Inject variant info into JS context\n",
    "view._remote_call(\"setParameters\", target=\"Stage\", kwargs={\n",
    "    \"tooltip\": False  # disable default tooltip for cleaner output\n",
    "})\n",
    "view._execute_js_code(f\"window.variantInfo = {variant_info}\")\n",
    "view._execute_js_code(js_code)\n",
    "\n",
    "# --- Step 9: Show viewer ---\n",
    "view.center()\n",
    "view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aabc3789-c3ec-4eae-af9b-7363800dc454",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Sinusoidal positional encoding (can be swapped for learnable).\"\"\"\n",
    "    def __init__(self, d_model, max_len=2048):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, D)\n",
    "        L = x.size(1)\n",
    "        return x + self.pe[:, :L, :]\n",
    "\n",
    "\n",
    "class VariantTransformerModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer module that integrates sequence embeddings + variant positional encoding.\n",
    "    Returns a pooled embedding at the variant position (or global pooling).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim,\n",
    "        n_heads=8,\n",
    "        ff_dim=2048,\n",
    "        n_layers=3,\n",
    "        dropout=0.1,\n",
    "        variant_embed_dim=None,\n",
    "        pooling=\"variant\"  # \"variant\" or \"mean\" or \"attn\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.pooling = pooling\n",
    "        self.pos_enc = PositionalEncoding(embed_dim)\n",
    "        self.input_proj = nn.Identity()  # if seq embeddings already have embed_dim; else nn.Linear(in_dim, embed_dim)\n",
    "\n",
    "        # learnable variant positional embedding (single vector added at variant position)\n",
    "        variant_embed_dim = variant_embed_dim or embed_dim\n",
    "        if variant_embed_dim != embed_dim:\n",
    "            self.variant_proj = nn.Linear(variant_embed_dim, embed_dim)\n",
    "        else:\n",
    "            self.variant_proj = None\n",
    "        self.variant_token = nn.Parameter(torch.randn(1, 1, embed_dim))  # can be added to variant pos\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # optional attention pooling head if pooling == \"attn\"\n",
    "        if pooling == \"attn\":\n",
    "            self.attn_pool = nn.Sequential(\n",
    "                nn.Linear(embed_dim, embed_dim),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(embed_dim, 1)\n",
    "            )\n",
    "\n",
    "    def forward(self, seq_embeddings, variant_pos=None, variant_extra=None, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        seq_embeddings: (B, L, D)  -- sequence-context embeddings (e.g., from protein LM or one-hot+embed)\n",
    "        variant_pos: tensor (B,) with integer positions (0..L-1) OR None if not applicable\n",
    "        variant_extra: optional extra learnable vector(s) per variant (B, D_var)\n",
    "        src_key_padding_mask: (B, L) bool mask where True==pad\n",
    "        \"\"\"\n",
    "        B, L, D = seq_embeddings.shape\n",
    "        x = self.input_proj(seq_embeddings)            # (B, L, D)\n",
    "        x = self.pos_enc(x)                            # add positional encoding\n",
    "\n",
    "        # inject variant token/encoding at variant positions\n",
    "        if variant_pos is not None:\n",
    "            # Option A: Add variant token vector to the embedding at that position:\n",
    "            # expand token to batch size and add to the position index\n",
    "            token = self.variant_token.expand(B, -1, -1)  # (B,1,D)\n",
    "            # create additive tensor\n",
    "            add_tensor = torch.zeros_like(x)              # (B, L, D)\n",
    "            for i in range(B):\n",
    "                p = int(variant_pos[i].item())\n",
    "                if 0 <= p < L:\n",
    "                    add_tensor[i, p : p+1, :] = token[i]\n",
    "            x = x + add_tensor\n",
    "\n",
    "            # Optionally also add variant_extra projected\n",
    "            if variant_extra is not None:\n",
    "                ve = variant_extra\n",
    "                if self.variant_proj is not None:\n",
    "                    ve = self.variant_proj(ve)  # (B, D)\n",
    "                add_tensor2 = torch.zeros_like(x)\n",
    "                for i in range(B):\n",
    "                    p = int(variant_pos[i].item())\n",
    "                    if 0 <= p < L:\n",
    "                        add_tensor2[i, p : p+1, :] = ve[i].unsqueeze(0)\n",
    "                x = x + add_tensor2\n",
    "\n",
    "        # Transformer expects (L, B, D)\n",
    "        x_t = x.transpose(0, 1)  # (L, B, D)\n",
    "        # src_key_padding_mask: (B, L) with True for pads\n",
    "        out = self.transformer(x_t, src_key_padding_mask=src_key_padding_mask)  # (L, B, D)\n",
    "        out = out.transpose(0, 1)  # (B, L, D)\n",
    "        out = self.layer_norm(out)\n",
    "\n",
    "        # Pooling\n",
    "        if self.pooling == \"variant\" and variant_pos is not None:\n",
    "            pooled = []\n",
    "            for i in range(B):\n",
    "                p = int(variant_pos[i].item())\n",
    "                if 0 <= p < L:\n",
    "                    pooled.append(out[i, p, :].unsqueeze(0))\n",
    "                else:\n",
    "                    pooled.append(out[i].mean(dim=0, keepdim=True))\n",
    "            pooled = torch.cat(pooled, dim=0)  # (B, D)\n",
    "        elif self.pooling == \"mean\":\n",
    "            if src_key_padding_mask is not None:\n",
    "                # mask out padding when averaging\n",
    "                mask = ~src_key_padding_mask  # True for valid tokens\n",
    "                mask = mask.unsqueeze(-1).float()  # (B, L, 1)\n",
    "                summed = (out * mask).sum(dim=1)\n",
    "                lengths = mask.sum(dim=1).clamp(min=1.0)\n",
    "                pooled = summed / lengths\n",
    "            else:\n",
    "                pooled = out.mean(dim=1)\n",
    "        elif self.pooling == \"attn\":\n",
    "            scores = self.attn_pool(out).squeeze(-1)  # (B, L)\n",
    "            if src_key_padding_mask is not None:\n",
    "                scores = scores.masked_fill(src_key_padding_mask, -1e9)\n",
    "            weights = torch.softmax(scores, dim=1).unsqueeze(-1)  # (B, L, 1)\n",
    "            pooled = (out * weights).sum(dim=1)\n",
    "        else:\n",
    "            # default fallback\n",
    "            pooled = out.mean(dim=1)\n",
    "\n",
    "        return pooled  # (B, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf51c05-e756-49a2-ae0b-41f76e4fa3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b043128c-754e-4ddf-a66b-6e0a978c8e40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# === CNN Module for Structural Patterns ===\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Author: Muskan Bansal (example)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Purpose: Extract structural embeddings from 2D contact/distance matrices\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Framework: TensorFlow / Keras\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     Input, Conv2D, MaxPooling2D, BatchNormalization,\n\u001b[0;32m     11\u001b[0m     Activation, GlobalAveragePooling2D, Dense, Dropout\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# === CNN Module for Structural Patterns ===\n",
    "# Author: Muskan Bansal (example)\n",
    "# Purpose: Extract structural embeddings from 2D contact/distance matrices\n",
    "# Framework: TensorFlow / Keras\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, BatchNormalization,\n",
    "    Activation, GlobalAveragePooling2D, Dense, Dropout\n",
    ")\n",
    "\n",
    "# === 1. Define CNN Model Function ===\n",
    "def build_structural_cnn(input_shape=(128, 128, 1), embedding_dim=256):\n",
    "    \"\"\"\n",
    "    Builds a CNN to extract structural embeddings from protein contact maps.\n",
    "    Args:\n",
    "        input_shape: Tuple -> shape of the input contact map (H, W, Channels)\n",
    "        embedding_dim: int -> dimension of output structural embedding\n",
    "    Returns:\n",
    "        model: Keras Model -> CNN encoder model\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # --- Block 1 ---\n",
    "    x = Conv2D(32, (5, 5), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # --- Block 2 ---\n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # --- Block 3 ---\n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # --- Global Feature Pooling ---\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # --- Fully Connected Projection ---\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(embedding_dim, activation='relu', name='structural_embedding')(x)\n",
    "\n",
    "    # --- Define and return model ---\n",
    "    model = Model(inputs, outputs, name='Structural_CNN_Module')\n",
    "    return model\n",
    "\n",
    "\n",
    "# === 2. Example Usage ===\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate a fake 2D contact/distance matrix (e.g. from AlphaFold)\n",
    "    contact_map = np.random.rand(128, 128)\n",
    "    contact_map = contact_map / contact_map.max()  # normalize to [0, 1]\n",
    "    contact_map = np.expand_dims(contact_map, axis=(0, -1))  # shape: (1, 128, 128, 1)\n",
    "\n",
    "    # Build and summarize model\n",
    "    cnn_model = build_structural_cnn(input_shape=(128, 128, 1))\n",
    "    cnn_model.summary()\n",
    "\n",
    "    # Generate embedding for the example contact map\n",
    "    embedding = cnn_model.predict(contact_map)\n",
    "    print(\"\\nâœ… Structural Embedding Shape:\", embedding.shape)\n",
    "    print(\"ðŸ”¹ First 10 embedding values:\", embedding[0, :10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6789f66d-b138-4935-8525-497882c9edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CNN Module for Structural Patterns (NumPy Version, Fixed) ===\n",
    "# Author: Muskan Bansal\n",
    "# Purpose: Extract structural embeddings from 2D contact/distance matrices\n",
    "# Framework: Pure NumPy + SciPy (no TensorFlow / PyTorch)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "class SimpleCNN:\n",
    "    def __init__(self):\n",
    "        # Define example convolution filters\n",
    "        self.filters = [\n",
    "            np.array([[1, -1], [-1, 1]]),           # edge pattern\n",
    "            np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]),  # Laplacian filter\n",
    "            np.ones((3, 3)) / 9                     # smoothing filter\n",
    "        ]\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def max_pool(self, feature_map, pool_size=2):\n",
    "        h, w = feature_map.shape\n",
    "\n",
    "        # Ensure divisibility by pool_size\n",
    "        h_trim = (h // pool_size) * pool_size\n",
    "        w_trim = (w // pool_size) * pool_size\n",
    "        feature_map = feature_map[:h_trim, :w_trim]\n",
    "\n",
    "        new_h, new_w = h_trim // pool_size, w_trim // pool_size\n",
    "        pooled = np.zeros((new_h, new_w))\n",
    "\n",
    "        for i in range(0, h_trim, pool_size):\n",
    "            for j in range(0, w_trim, pool_size):\n",
    "                region = feature_map[i:i+pool_size, j:j+pool_size]\n",
    "                pooled[i//pool_size, j//pool_size] = np.max(region)\n",
    "        return pooled\n",
    "\n",
    "    def global_avg_pool(self, feature_maps):\n",
    "        return np.array([np.mean(fm) for fm in feature_maps])\n",
    "\n",
    "    def forward(self, matrix):\n",
    "        \"\"\"Input: 2D contact/distance matrix (numpy array)\"\"\"\n",
    "        feature_maps = []\n",
    "        for f in self.filters:\n",
    "            conv = convolve2d(matrix, f, mode='valid')\n",
    "            activated = self.relu(conv)\n",
    "            pooled = self.max_pool(activated, pool_size=2)\n",
    "            feature_maps.append(pooled)\n",
    "\n",
    "        # Combine all maps via global average pooling\n",
    "        embedding = self.global_avg_pool(feature_maps)\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f0b24d-24b5-4e3e-bb02-6a4b40c7a8ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70e2ad3-6ef8-4740-9606-ae208a7fd8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
