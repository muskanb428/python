{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab3b4bb-c18f-4ab7-87e5-6f60b259443b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.9.0-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.9.0-cp313-cp313-win_amd64.whl (109.3 MB)\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/109.3 MB 1.3 MB/s eta 0:01:25\n",
      "   ---------------------------------------- 0.8/109.3 MB 1.3 MB/s eta 0:01:26\n",
      "   ---------------------------------------- 1.0/109.3 MB 1.3 MB/s eta 0:01:27\n",
      "   ---------------------------------------- 1.3/109.3 MB 1.3 MB/s eta 0:01:26\n",
      "    --------------------------------------- 1.6/109.3 MB 1.3 MB/s eta 0:01:25\n",
      "    --------------------------------------- 1.8/109.3 MB 1.3 MB/s eta 0:01:25\n",
      "    --------------------------------------- 2.1/109.3 MB 1.3 MB/s eta 0:01:25\n",
      "    --------------------------------------- 2.4/109.3 MB 1.3 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 2.9/109.3 MB 1.3 MB/s eta 0:01:24\n",
      "   - -------------------------------------- 3.1/109.3 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 3.4/109.3 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 3.7/109.3 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 3.9/109.3 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 4.2/109.3 MB 1.3 MB/s eta 0:01:23\n",
      "   - -------------------------------------- 4.5/109.3 MB 1.3 MB/s eta 0:01:22\n",
      "   - -------------------------------------- 4.7/109.3 MB 1.3 MB/s eta 0:01:22\n",
      "   - -------------------------------------- 5.0/109.3 MB 1.3 MB/s eta 0:01:22\n",
      "   - -------------------------------------- 5.2/109.3 MB 1.3 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 5.5/109.3 MB 1.3 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 5.8/109.3 MB 1.3 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 6.0/109.3 MB 1.3 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 6.3/109.3 MB 1.3 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 6.6/109.3 MB 1.3 MB/s eta 0:01:20\n",
      "   -- ------------------------------------- 6.8/109.3 MB 1.3 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 7.1/109.3 MB 1.3 MB/s eta 0:01:21\n",
      "   -- ------------------------------------- 7.3/109.3 MB 1.3 MB/s eta 0:01:20\n",
      "   -- ------------------------------------- 7.3/109.3 MB 1.3 MB/s eta 0:01:20\n",
      "   -- ------------------------------------- 7.6/109.3 MB 1.2 MB/s eta 0:01:23\n",
      "   -- ------------------------------------- 7.9/109.3 MB 1.2 MB/s eta 0:01:23\n",
      "   -- ------------------------------------- 8.1/109.3 MB 1.2 MB/s eta 0:01:22\n",
      "   --- ------------------------------------ 8.4/109.3 MB 1.2 MB/s eta 0:01:22\n",
      "   --- ------------------------------------ 8.7/109.3 MB 1.2 MB/s eta 0:01:22\n",
      "   --- ------------------------------------ 8.9/109.3 MB 1.2 MB/s eta 0:01:21\n",
      "   --- ------------------------------------ 9.2/109.3 MB 1.2 MB/s eta 0:01:21\n",
      "   --- ------------------------------------ 9.4/109.3 MB 1.2 MB/s eta 0:01:21\n",
      "   --- ------------------------------------ 9.7/109.3 MB 1.2 MB/s eta 0:01:21\n",
      "   --- ------------------------------------ 10.0/109.3 MB 1.2 MB/s eta 0:01:20\n",
      "   --- ------------------------------------ 10.2/109.3 MB 1.2 MB/s eta 0:01:20\n",
      "   --- ------------------------------------ 10.5/109.3 MB 1.3 MB/s eta 0:01:20\n",
      "   --- ------------------------------------ 10.7/109.3 MB 1.2 MB/s eta 0:01:19\n",
      "   ---- ----------------------------------- 11.0/109.3 MB 1.3 MB/s eta 0:01:19\n",
      "   ---- ----------------------------------- 11.3/109.3 MB 1.3 MB/s eta 0:01:19\n",
      "   ---- ----------------------------------- 11.5/109.3 MB 1.3 MB/s eta 0:01:19\n",
      "   ---- ----------------------------------- 11.8/109.3 MB 1.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 12.1/109.3 MB 1.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 12.3/109.3 MB 1.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 12.6/109.3 MB 1.3 MB/s eta 0:01:18\n",
      "   ---- ----------------------------------- 12.8/109.3 MB 1.3 MB/s eta 0:01:17\n",
      "   ---- ----------------------------------- 13.1/109.3 MB 1.3 MB/s eta 0:01:17\n",
      "   ---- ----------------------------------- 13.6/109.3 MB 1.3 MB/s eta 0:01:16\n",
      "   ---- ----------------------------------- 13.6/109.3 MB 1.3 MB/s eta 0:01:16\n",
      "   ----- ---------------------------------- 13.9/109.3 MB 1.3 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 13.9/109.3 MB 1.3 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 14.2/109.3 MB 1.2 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 14.4/109.3 MB 1.2 MB/s eta 0:01:18\n",
      "   ----- ---------------------------------- 14.7/109.3 MB 1.2 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 14.9/109.3 MB 1.2 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 15.2/109.3 MB 1.2 MB/s eta 0:01:17\n",
      "   ----- ---------------------------------- 15.5/109.3 MB 1.2 MB/s eta 0:01:16\n",
      "   ----- ---------------------------------- 15.7/109.3 MB 1.2 MB/s eta 0:01:16\n",
      "   ----- ---------------------------------- 16.0/109.3 MB 1.2 MB/s eta 0:01:16\n",
      "   ------ --------------------------------- 16.5/109.3 MB 1.2 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 16.8/109.3 MB 1.2 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 17.0/109.3 MB 1.2 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 17.3/109.3 MB 1.2 MB/s eta 0:01:15\n",
      "   ------ --------------------------------- 17.6/109.3 MB 1.2 MB/s eta 0:01:14\n",
      "   ------ --------------------------------- 17.8/109.3 MB 1.2 MB/s eta 0:01:14\n",
      "   ------ --------------------------------- 18.1/109.3 MB 1.2 MB/s eta 0:01:14\n",
      "   ------ --------------------------------- 18.4/109.3 MB 1.2 MB/s eta 0:01:14\n",
      "   ------ --------------------------------- 18.6/109.3 MB 1.2 MB/s eta 0:01:13\n",
      "   ------ --------------------------------- 18.9/109.3 MB 1.2 MB/s eta 0:01:13\n",
      "   ------- -------------------------------- 19.1/109.3 MB 1.2 MB/s eta 0:01:13\n",
      "   ------- -------------------------------- 19.4/109.3 MB 1.2 MB/s eta 0:01:13\n",
      "   ------- -------------------------------- 19.7/109.3 MB 1.2 MB/s eta 0:01:12\n",
      "   ------- -------------------------------- 19.9/109.3 MB 1.2 MB/s eta 0:01:12\n",
      "   ------- -------------------------------- 20.2/109.3 MB 1.2 MB/s eta 0:01:12\n",
      "   ------- -------------------------------- 20.4/109.3 MB 1.2 MB/s eta 0:01:12\n",
      "   ------- -------------------------------- 20.7/109.3 MB 1.2 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 21.0/109.3 MB 1.2 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 21.2/109.3 MB 1.3 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 21.2/109.3 MB 1.3 MB/s eta 0:01:11\n",
      "   ------- -------------------------------- 21.5/109.3 MB 1.2 MB/s eta 0:01:12\n",
      "   ------- -------------------------------- 21.8/109.3 MB 1.2 MB/s eta 0:01:12\n",
      "   -------- ------------------------------- 22.0/109.3 MB 1.2 MB/s eta 0:01:11\n",
      "   -------- ------------------------------- 22.3/109.3 MB 1.2 MB/s eta 0:01:11\n",
      "   -------- ------------------------------- 22.5/109.3 MB 1.2 MB/s eta 0:01:11\n",
      "   -------- ------------------------------- 22.8/109.3 MB 1.2 MB/s eta 0:01:11\n",
      "   -------- ------------------------------- 23.1/109.3 MB 1.2 MB/s eta 0:01:10\n",
      "   -------- ------------------------------- 23.3/109.3 MB 1.2 MB/s eta 0:01:10\n",
      "   -------- ------------------------------- 23.6/109.3 MB 1.2 MB/s eta 0:01:10\n",
      "   -------- ------------------------------- 23.9/109.3 MB 1.2 MB/s eta 0:01:10\n",
      "   -------- ------------------------------- 24.1/109.3 MB 1.2 MB/s eta 0:01:09\n",
      "   -------- ------------------------------- 24.4/109.3 MB 1.2 MB/s eta 0:01:09\n",
      "   --------- ------------------------------ 24.6/109.3 MB 1.2 MB/s eta 0:01:09\n",
      "   --------- ------------------------------ 24.9/109.3 MB 1.2 MB/s eta 0:01:09\n",
      "   --------- ------------------------------ 25.2/109.3 MB 1.2 MB/s eta 0:01:08\n",
      "   --------- ------------------------------ 25.4/109.3 MB 1.2 MB/s eta 0:01:08\n",
      "   --------- ------------------------------ 25.7/109.3 MB 1.2 MB/s eta 0:01:08\n",
      "   --------- ------------------------------ 26.0/109.3 MB 1.2 MB/s eta 0:01:08\n",
      "   --------- ------------------------------ 26.2/109.3 MB 1.2 MB/s eta 0:01:07\n",
      "   --------- ------------------------------ 26.5/109.3 MB 1.2 MB/s eta 0:01:07\n",
      "   --------- ------------------------------ 26.7/109.3 MB 1.2 MB/s eta 0:01:07\n",
      "   --------- ------------------------------ 27.0/109.3 MB 1.2 MB/s eta 0:01:07\n",
      "   --------- ------------------------------ 27.3/109.3 MB 1.2 MB/s eta 0:01:06\n",
      "   ---------- ----------------------------- 27.5/109.3 MB 1.2 MB/s eta 0:01:06\n",
      "   ---------- ----------------------------- 27.8/109.3 MB 1.2 MB/s eta 0:01:06\n",
      "   ---------- ----------------------------- 28.0/109.3 MB 1.2 MB/s eta 0:01:06\n",
      "   ---------- ----------------------------- 28.3/109.3 MB 1.2 MB/s eta 0:01:06\n",
      "   ---------- ----------------------------- 28.6/109.3 MB 1.2 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 28.6/109.3 MB 1.2 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 28.8/109.3 MB 1.2 MB/s eta 0:01:06\n",
      "   ---------- ----------------------------- 29.1/109.3 MB 1.2 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 29.4/109.3 MB 1.2 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 29.6/109.3 MB 1.2 MB/s eta 0:01:05\n",
      "   ---------- ----------------------------- 29.9/109.3 MB 1.2 MB/s eta 0:01:05\n",
      "   ----------- ---------------------------- 30.1/109.3 MB 1.2 MB/s eta 0:01:05\n",
      "   ----------- ---------------------------- 30.4/109.3 MB 1.2 MB/s eta 0:01:04\n",
      "   ----------- ---------------------------- 30.7/109.3 MB 1.2 MB/s eta 0:01:04\n",
      "   ----------- ---------------------------- 30.9/109.3 MB 1.2 MB/s eta 0:01:04\n",
      "   ----------- ---------------------------- 31.2/109.3 MB 1.2 MB/s eta 0:01:04\n",
      "   ----------- ---------------------------- 31.5/109.3 MB 1.2 MB/s eta 0:01:03\n",
      "   ----------- ---------------------------- 31.7/109.3 MB 1.2 MB/s eta 0:01:03\n",
      "   ----------- ---------------------------- 32.0/109.3 MB 1.2 MB/s eta 0:01:03\n",
      "   ----------- ---------------------------- 32.2/109.3 MB 1.2 MB/s eta 0:01:03\n",
      "   ----------- ---------------------------- 32.8/109.3 MB 1.2 MB/s eta 0:01:02\n",
      "   ------------ --------------------------- 33.0/109.3 MB 1.2 MB/s eta 0:01:02\n",
      "   ------------ --------------------------- 33.3/109.3 MB 1.2 MB/s eta 0:01:02\n",
      "   ------------ --------------------------- 33.6/109.3 MB 1.2 MB/s eta 0:01:02\n",
      "   ------------ --------------------------- 33.8/109.3 MB 1.2 MB/s eta 0:01:01\n",
      "   ------------ --------------------------- 34.1/109.3 MB 1.2 MB/s eta 0:01:01\n",
      "   ------------ --------------------------- 34.3/109.3 MB 1.2 MB/s eta 0:01:01\n",
      "   ------------ --------------------------- 34.6/109.3 MB 1.2 MB/s eta 0:01:01\n",
      "   ------------ --------------------------- 34.9/109.3 MB 1.2 MB/s eta 0:01:00\n",
      "   ------------ --------------------------- 35.1/109.3 MB 1.2 MB/s eta 0:01:00\n",
      "   ------------ --------------------------- 35.4/109.3 MB 1.2 MB/s eta 0:01:00\n",
      "   ------------- -------------------------- 35.7/109.3 MB 1.2 MB/s eta 0:01:00\n",
      "   ------------- -------------------------- 35.9/109.3 MB 1.2 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 35.9/109.3 MB 1.2 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 36.2/109.3 MB 1.2 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 36.4/109.3 MB 1.2 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 36.7/109.3 MB 1.2 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 37.0/109.3 MB 1.2 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 37.2/109.3 MB 1.2 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 37.5/109.3 MB 1.2 MB/s eta 0:00:59\n",
      "   ------------- -------------------------- 37.7/109.3 MB 1.2 MB/s eta 0:00:58\n",
      "   ------------- -------------------------- 38.0/109.3 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 38.3/109.3 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 38.5/109.3 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 38.8/109.3 MB 1.2 MB/s eta 0:00:58\n",
      "   -------------- ------------------------- 39.1/109.3 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------- ------------------------- 39.3/109.3 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------- ------------------------- 39.6/109.3 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------- ------------------------- 39.8/109.3 MB 1.2 MB/s eta 0:00:57\n",
      "   -------------- ------------------------- 40.1/109.3 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 40.4/109.3 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 40.6/109.3 MB 1.2 MB/s eta 0:00:56\n",
      "   -------------- ------------------------- 40.9/109.3 MB 1.2 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 41.2/109.3 MB 1.2 MB/s eta 0:00:56\n",
      "   --------------- ------------------------ 41.4/109.3 MB 1.2 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 41.7/109.3 MB 1.2 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 41.9/109.3 MB 1.2 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 42.2/109.3 MB 1.2 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 42.5/109.3 MB 1.2 MB/s eta 0:00:55\n",
      "   --------------- ------------------------ 42.7/109.3 MB 1.2 MB/s eta 0:00:54\n",
      "   --------------- ------------------------ 43.0/109.3 MB 1.2 MB/s eta 0:00:54\n",
      "   --------------- ------------------------ 43.3/109.3 MB 1.2 MB/s eta 0:00:54\n",
      "   --------------- ------------------------ 43.5/109.3 MB 1.2 MB/s eta 0:00:54\n",
      "   --------------- ------------------------ 43.5/109.3 MB 1.2 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 43.8/109.3 MB 1.2 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 44.0/109.3 MB 1.2 MB/s eta 0:00:54\n",
      "   ---------------- ----------------------- 44.3/109.3 MB 1.2 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 44.6/109.3 MB 1.2 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 44.8/109.3 MB 1.2 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 45.1/109.3 MB 1.2 MB/s eta 0:00:53\n",
      "   ---------------- ----------------------- 45.4/109.3 MB 1.2 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 45.6/109.3 MB 1.2 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 45.9/109.3 MB 1.2 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 46.1/109.3 MB 1.2 MB/s eta 0:00:52\n",
      "   ---------------- ----------------------- 46.4/109.3 MB 1.2 MB/s eta 0:00:52\n",
      "   ----------------- ---------------------- 46.7/109.3 MB 1.2 MB/s eta 0:00:51\n",
      "   ----------------- ---------------------- 46.9/109.3 MB 1.2 MB/s eta 0:00:51\n",
      "   ----------------- ---------------------- 47.2/109.3 MB 1.2 MB/s eta 0:00:51\n",
      "   ----------------- ---------------------- 47.4/109.3 MB 1.2 MB/s eta 0:00:51\n",
      "   ----------------- ---------------------- 47.7/109.3 MB 1.2 MB/s eta 0:00:51\n",
      "   ----------------- ---------------------- 48.0/109.3 MB 1.2 MB/s eta 0:00:50\n",
      "   ----------------- ---------------------- 48.2/109.3 MB 1.2 MB/s eta 0:00:50\n",
      "   ----------------- ---------------------- 48.5/109.3 MB 1.2 MB/s eta 0:00:50\n",
      "   ----------------- ---------------------- 48.8/109.3 MB 1.2 MB/s eta 0:00:50\n",
      "   ----------------- ---------------------- 49.0/109.3 MB 1.2 MB/s eta 0:00:49\n",
      "   ------------------ --------------------- 49.3/109.3 MB 1.2 MB/s eta 0:00:49\n",
      "   ------------------ --------------------- 49.5/109.3 MB 1.2 MB/s eta 0:00:49\n",
      "   ------------------ --------------------- 50.1/109.3 MB 1.2 MB/s eta 0:00:49\n",
      "   ------------------ --------------------- 50.3/109.3 MB 1.2 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 50.6/109.3 MB 1.2 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 50.9/109.3 MB 1.2 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 50.9/109.3 MB 1.2 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 50.9/109.3 MB 1.2 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 51.1/109.3 MB 1.2 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 51.4/109.3 MB 1.2 MB/s eta 0:00:48\n",
      "   ------------------ --------------------- 51.6/109.3 MB 1.2 MB/s eta 0:00:47\n",
      "   ------------------ --------------------- 51.9/109.3 MB 1.2 MB/s eta 0:00:47\n",
      "   ------------------- -------------------- 52.2/109.3 MB 1.2 MB/s eta 0:00:47\n",
      "   ------------------- -------------------- 52.4/109.3 MB 1.2 MB/s eta 0:00:47\n",
      "   ------------------- -------------------- 52.7/109.3 MB 1.2 MB/s eta 0:00:47\n",
      "   ------------------- -------------------- 53.0/109.3 MB 1.2 MB/s eta 0:00:46\n",
      "   ------------------- -------------------- 53.2/109.3 MB 1.2 MB/s eta 0:00:46\n",
      "   ------------------- -------------------- 53.5/109.3 MB 1.2 MB/s eta 0:00:46\n",
      "   ------------------- -------------------- 53.7/109.3 MB 1.2 MB/s eta 0:00:46\n",
      "   ------------------- -------------------- 54.0/109.3 MB 1.2 MB/s eta 0:00:46\n",
      "   ------------------- -------------------- 54.0/109.3 MB 1.2 MB/s eta 0:00:46\n",
      "   ------------------- -------------------- 54.5/109.3 MB 1.2 MB/s eta 0:00:45\n",
      "   -------------------- ------------------- 54.8/109.3 MB 1.2 MB/s eta 0:00:45\n",
      "   -------------------- ------------------- 55.1/109.3 MB 1.2 MB/s eta 0:00:45\n",
      "   -------------------- ------------------- 55.3/109.3 MB 1.2 MB/s eta 0:00:45\n",
      "   -------------------- ------------------- 55.6/109.3 MB 1.2 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 55.8/109.3 MB 1.2 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 56.1/109.3 MB 1.2 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 56.4/109.3 MB 1.2 MB/s eta 0:00:44\n",
      "   -------------------- ------------------- 56.9/109.3 MB 1.2 MB/s eta 0:00:43\n",
      "   -------------------- ------------------- 57.1/109.3 MB 1.2 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 57.4/109.3 MB 1.2 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 57.7/109.3 MB 1.2 MB/s eta 0:00:43\n",
      "   --------------------- ------------------ 57.9/109.3 MB 1.2 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 58.2/109.3 MB 1.2 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 58.2/109.3 MB 1.2 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 58.5/109.3 MB 1.2 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 58.7/109.3 MB 1.2 MB/s eta 0:00:42\n",
      "   --------------------- ------------------ 59.0/109.3 MB 1.2 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 59.2/109.3 MB 1.2 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 59.5/109.3 MB 1.2 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 59.8/109.3 MB 1.2 MB/s eta 0:00:41\n",
      "   --------------------- ------------------ 60.0/109.3 MB 1.2 MB/s eta 0:00:41\n",
      "   ---------------------- ----------------- 60.3/109.3 MB 1.2 MB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 60.6/109.3 MB 1.2 MB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 60.8/109.3 MB 1.2 MB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 61.1/109.3 MB 1.2 MB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 61.3/109.3 MB 1.2 MB/s eta 0:00:40\n",
      "   ---------------------- ----------------- 61.6/109.3 MB 1.2 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 61.9/109.3 MB 1.2 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 62.1/109.3 MB 1.2 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 62.4/109.3 MB 1.2 MB/s eta 0:00:39\n",
      "   ---------------------- ----------------- 62.7/109.3 MB 1.2 MB/s eta 0:00:39\n",
      "   ----------------------- ---------------- 62.9/109.3 MB 1.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 63.2/109.3 MB 1.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 63.4/109.3 MB 1.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 63.7/109.3 MB 1.2 MB/s eta 0:00:38\n",
      "   ----------------------- ---------------- 64.0/109.3 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 64.2/109.3 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 64.5/109.3 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 64.7/109.3 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 65.0/109.3 MB 1.2 MB/s eta 0:00:37\n",
      "   ----------------------- ---------------- 65.3/109.3 MB 1.2 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 65.5/109.3 MB 1.2 MB/s eta 0:00:36\n",
      "   ----------------------- ---------------- 65.5/109.3 MB 1.2 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 65.8/109.3 MB 1.2 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 65.8/109.3 MB 1.2 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 66.1/109.3 MB 1.2 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 66.3/109.3 MB 1.2 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 66.6/109.3 MB 1.2 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 67.1/109.3 MB 1.2 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 67.4/109.3 MB 1.2 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 67.6/109.3 MB 1.2 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 67.9/109.3 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------ --------------- 68.2/109.3 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 68.4/109.3 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 68.7/109.3 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 68.9/109.3 MB 1.2 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 69.2/109.3 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 69.5/109.3 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 69.7/109.3 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 70.0/109.3 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 70.3/109.3 MB 1.2 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 70.5/109.3 MB 1.2 MB/s eta 0:00:32\n",
      "   ------------------------- -------------- 70.8/109.3 MB 1.2 MB/s eta 0:00:32\n",
      "   -------------------------- ------------- 71.0/109.3 MB 1.2 MB/s eta 0:00:32\n",
      "   -------------------------- ------------- 71.3/109.3 MB 1.2 MB/s eta 0:00:32\n",
      "   -------------------------- ------------- 71.6/109.3 MB 1.2 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 71.8/109.3 MB 1.2 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 72.1/109.3 MB 1.2 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 72.4/109.3 MB 1.2 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 72.6/109.3 MB 1.2 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 72.9/109.3 MB 1.2 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 72.9/109.3 MB 1.2 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 73.1/109.3 MB 1.2 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 73.4/109.3 MB 1.2 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 73.7/109.3 MB 1.2 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 73.9/109.3 MB 1.2 MB/s eta 0:00:30\n",
      "   --------------------------- ------------ 74.2/109.3 MB 1.2 MB/s eta 0:00:29\n",
      "   --------------------------- ------------ 74.4/109.3 MB 1.2 MB/s eta 0:00:29\n",
      "   --------------------------- ------------ 74.7/109.3 MB 1.2 MB/s eta 0:00:29\n",
      "   --------------------------- ------------ 75.0/109.3 MB 1.2 MB/s eta 0:00:29\n",
      "   --------------------------- ------------ 75.2/109.3 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 75.2/109.3 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 75.8/109.3 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 76.0/109.3 MB 1.2 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 76.3/109.3 MB 1.2 MB/s eta 0:00:28\n",
      "   ---------------------------- ----------- 76.5/109.3 MB 1.2 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 76.8/109.3 MB 1.2 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 77.1/109.3 MB 1.2 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 77.3/109.3 MB 1.2 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 77.6/109.3 MB 1.2 MB/s eta 0:00:27\n",
      "   ---------------------------- ----------- 77.9/109.3 MB 1.2 MB/s eta 0:00:26\n",
      "   ---------------------------- ----------- 78.1/109.3 MB 1.2 MB/s eta 0:00:26\n",
      "   ---------------------------- ----------- 78.4/109.3 MB 1.2 MB/s eta 0:00:26\n",
      "   ---------------------------- ----------- 78.6/109.3 MB 1.2 MB/s eta 0:00:26\n",
      "   ---------------------------- ----------- 78.9/109.3 MB 1.2 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 79.2/109.3 MB 1.2 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 79.4/109.3 MB 1.2 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 79.7/109.3 MB 1.2 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 80.0/109.3 MB 1.2 MB/s eta 0:00:25\n",
      "   ----------------------------- ---------- 80.2/109.3 MB 1.2 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 80.2/109.3 MB 1.2 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 80.5/109.3 MB 1.2 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 80.7/109.3 MB 1.2 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 81.0/109.3 MB 1.2 MB/s eta 0:00:24\n",
      "   ----------------------------- ---------- 81.3/109.3 MB 1.2 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 81.5/109.3 MB 1.2 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 81.8/109.3 MB 1.2 MB/s eta 0:00:23\n",
      "   ------------------------------ --------- 82.1/109.3 MB 1.2 MB/s eta 0:00:23\n",
      "   ------------------------------ --------- 82.3/109.3 MB 1.2 MB/s eta 0:00:23\n",
      "   ------------------------------ --------- 82.6/109.3 MB 1.2 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 82.8/109.3 MB 1.2 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 83.1/109.3 MB 1.2 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 83.4/109.3 MB 1.2 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 83.6/109.3 MB 1.2 MB/s eta 0:00:22\n",
      "   ------------------------------ --------- 83.9/109.3 MB 1.2 MB/s eta 0:00:21\n",
      "   ------------------------------ --------- 84.1/109.3 MB 1.2 MB/s eta 0:00:21\n",
      "   ------------------------------ --------- 84.4/109.3 MB 1.2 MB/s eta 0:00:21\n",
      "   ------------------------------ --------- 84.7/109.3 MB 1.2 MB/s eta 0:00:21\n",
      "   ------------------------------- -------- 84.9/109.3 MB 1.2 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 85.2/109.3 MB 1.2 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 85.5/109.3 MB 1.2 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 85.7/109.3 MB 1.2 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 86.0/109.3 MB 1.2 MB/s eta 0:00:20\n",
      "   ------------------------------- -------- 86.2/109.3 MB 1.2 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 86.5/109.3 MB 1.2 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 86.8/109.3 MB 1.2 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 87.0/109.3 MB 1.2 MB/s eta 0:00:19\n",
      "   ------------------------------- -------- 87.3/109.3 MB 1.2 MB/s eta 0:00:19\n",
      "   -------------------------------- ------- 87.6/109.3 MB 1.2 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 87.6/109.3 MB 1.2 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 87.8/109.3 MB 1.2 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 88.1/109.3 MB 1.2 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 88.3/109.3 MB 1.2 MB/s eta 0:00:18\n",
      "   -------------------------------- ------- 88.6/109.3 MB 1.2 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 88.9/109.3 MB 1.2 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 89.1/109.3 MB 1.2 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 89.4/109.3 MB 1.2 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 89.7/109.3 MB 1.2 MB/s eta 0:00:17\n",
      "   -------------------------------- ------- 89.9/109.3 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 90.2/109.3 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 90.4/109.3 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 90.7/109.3 MB 1.2 MB/s eta 0:00:16\n",
      "   --------------------------------- ------ 91.0/109.3 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 91.2/109.3 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 91.5/109.3 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 91.8/109.3 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 92.0/109.3 MB 1.2 MB/s eta 0:00:15\n",
      "   --------------------------------- ------ 92.3/109.3 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 92.5/109.3 MB 1.2 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 92.8/109.3 MB 1.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 93.1/109.3 MB 1.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 93.3/109.3 MB 1.2 MB/s eta 0:00:14\n",
      "   ---------------------------------- ----- 93.6/109.3 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 93.8/109.3 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 94.1/109.3 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 94.4/109.3 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 94.6/109.3 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 94.6/109.3 MB 1.2 MB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 94.9/109.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 95.2/109.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 95.4/109.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 95.7/109.3 MB 1.2 MB/s eta 0:00:12\n",
      "   ----------------------------------- ---- 95.9/109.3 MB 1.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 96.2/109.3 MB 1.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 96.5/109.3 MB 1.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 96.7/109.3 MB 1.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 97.0/109.3 MB 1.2 MB/s eta 0:00:11\n",
      "   ----------------------------------- ---- 97.3/109.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 97.5/109.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 97.8/109.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 98.0/109.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 98.3/109.3 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------------------------------ --- 98.6/109.3 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 98.8/109.3 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 99.1/109.3 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 99.4/109.3 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 99.6/109.3 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 99.9/109.3 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 100.1/109.3 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 100.4/109.3 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 100.7/109.3 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 100.9/109.3 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 101.2/109.3 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 101.4/109.3 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 101.7/109.3 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 102.0/109.3 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 102.2/109.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 102.2/109.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 102.5/109.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 102.8/109.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 103.0/109.3 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 103.3/109.3 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 103.5/109.3 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 103.8/109.3 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 104.1/109.3 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 104.3/109.3 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 104.6/109.3 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 104.9/109.3 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 105.1/109.3 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 105.4/109.3 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 105.6/109.3 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 105.9/109.3 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 106.2/109.3 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 106.4/109.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  106.7/109.3 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------------------------------  107.0/109.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  107.2/109.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  107.5/109.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  107.7/109.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  108.0/109.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  108.3/109.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  108.5/109.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  108.8/109.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.3 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 109.3/109.3 MB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: torch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\muska\\\\anaconda3\\\\Lib\\\\site-packages\\\\torch-2.9.0.dist-info\\\\RECORD_2fahza5.tmp' -> 'C:\\\\Users\\\\muska\\\\anaconda3\\\\Lib\\\\site-packages\\\\torch-2.9.0.dist-info\\\\RECORD'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659fd558-becf-4861-9d00-fef51ce8d949",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 69 (3344132171.py, line 70)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 70\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 69\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"Sinusoidal positional encoding (can be swapped for learnable).\"\"\"\n",
    "    def __init__(self, d_model, max_len=2048):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, D)\n",
    "        L = x.size(1)\n",
    "        return x + self.pe[:, :L, :]\n",
    "\n",
    "\n",
    "class VariantTransformerModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer module that integrates sequence embeddings + variant positional encoding.\n",
    "    Returns a pooled embedding at the variant position (or global pooling).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim,\n",
    "        n_heads=8,\n",
    "        ff_dim=2048,\n",
    "        n_layers=3,\n",
    "        dropout=0.1,\n",
    "        variant_embed_dim=None,\n",
    "         pooling=\"variant\"  # \"variant\" or \"mean\" or \"attn\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.pooling = pooling\n",
    "        self.pos_enc = PositionalEncoding(embed_dim)\n",
    "        self.input_proj = nn.Identity()  # if seq embeddings already have embed_dim; else nn.Linear(in_dim, embed_dim)\n",
    "\n",
    "        # learnable variant positional embedding (single vector added at variant position)\n",
    "        variant_embed_dim = variant_embed_dim or embed_dim\n",
    "        if variant_embed_dim != embed_dim:\n",
    "            self.variant_proj = nn.Linear(variant_embed_dim, embed_dim)\n",
    "        else:\n",
    "            self.variant_proj = None\n",
    "        self.variant_token = nn.Parameter(torch.randn(1, 1, embed_dim))  # can be added to variant pos\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\"\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # optional attention pooling head if pooling == \"attn\"\n",
    "        if pooling == \"attn\":\n",
    "            self.attn_pool = nn.Sequential(\n",
    "                nn.Linear(embed_dim, embed_dim),\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(embed_dim, 1)\n",
    "            )\n",
    "            def forward(self, seq_embeddings, variant_pos=None, variant_extra=None, src_key_padding_mask=None):\n",
    "        \"\"\"\n",
    "        seq_embeddings: (B, L, D)  -- sequence-context embeddings (e.g., from protein LM or one-hot+embed)\n",
    "        variant_pos: tensor (B,) with integer positions (0..L-1) OR None if not applicable\n",
    "        variant_extra: optional extra learnable vector(s) per variant (B, D_var)\n",
    "        src_key_padding_mask: (B, L) bool mask where True==pad\n",
    "        \n",
    "        \"\"\"\n",
    "        B, L, D = seq_embeddings.shape\n",
    "        x = self.input_proj(seq_embeddings)            # (B, L, D)\n",
    "        x = self.pos_enc(x)                            # add positional encoding\n",
    "\n",
    "        # inject variant token/encoding at variant positions\n",
    "        if variant_pos is not None:\n",
    "            # Option A: Add variant token vector to the embedding at that position:\n",
    "            # expand token to batch size and add to the position index\n",
    "            token = self.variant_token.expand(B, -1, -1)  # (B,1,D)\n",
    "            # create additive tensor\n",
    "            add_tensor = torch.zeros_like(x)              # (B, L, D)\n",
    "            for i in range(B):\n",
    "                p = int(variant_pos[i].item())\n",
    "                if 0 <= p < L:\n",
    "                    add_tensor[i, p : p+1, :] = token[i]\n",
    "            x = x + add_tensor\n",
    "\n",
    "            # Optionally also add variant_extra projected\n",
    "            if variant_extra is not None:\n",
    "                ve = variant_extra\n",
    "                if self.variant_proj is not None:\n",
    "                    ve = self.variant_proj(ve)  # (B, D)\n",
    "                add_tensor2 = torch.zeros_like(x)\n",
    "                for i in range(B):\n",
    "                    p = int(variant_pos[i].item())\n",
    "                    if 0 <= p < L:\n",
    "                        add_tensor2[i, p : p+1, :] = ve[i].unsqueeze(0)\n",
    "                x = x + add_tensor2\n",
    "                  # Transformer expects (L, B, D)\n",
    "        x_t = x.transpose(0, 1)  # (L, B, D)\n",
    "        # src_key_padding_mask: (B, L) with True for pads\n",
    "        out = self.transformer(x_t, src_key_padding_mask=src_key_padding_mask)  # (L, B, D)\n",
    "        out = out.transpose(0, 1)  # (B, L, D)\n",
    "        out = self.layer_norm(out)\n",
    "\n",
    "        # Pooling\n",
    "        if self.pooling == \"variant\" and variant_pos is not None:\n",
    "            pooled = []\n",
    "            for i in range(B):\n",
    "                p = int(variant_pos[i].item())\n",
    "                if 0 <= p < L:\n",
    "                    pooled.append(out[i, p, :].unsqueeze(0))\n",
    "                else:\n",
    "                    pooled.append(out[i].mean(dim=0, keepdim=True))\n",
    "            pooled = torch.cat(pooled, dim=0)  # (B, D)\n",
    "        elif self.pooling == \"mean\":\n",
    "            if src_key_padding_mask is not None:\n",
    "                # mask out padding when averaging\n",
    "                mask = ~src_key_padding_mask  # True for valid tokens\n",
    "                mask = mask.unsqueeze(-1).float()  # (B, L, 1)\n",
    "                summed = (out * mask).sum(dim=1)\n",
    "                lengths = mask.sum(dim=1).clamp(min=1.0)\n",
    "                pooled = summed / lengths\n",
    "            else:\n",
    "                pooled = out.mean(dim=1)\n",
    "        elif self.pooling == \"attn\":\n",
    "            scores = self.attn_pool(out).squeeze(-1)  # (B, L)\n",
    "            if src_key_padding_mask is not None:\n",
    "                scores = scores.masked_fill(src_key_padding_mask, -1e9)\n",
    "            weights = torch.softmax(scores, dim=1).unsqueeze(-1)  # (B, L, 1)\n",
    "            pooled = (out * weights).sum(dim=1)\n",
    "        else:\n",
    "            # default fallback\n",
    "            pooled = out.mean(dim=1)\n",
    "             return pooled  # (B, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba79569-8fb6-4370-91fa-5a719d3b7519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structural Embedding Vector Shape: torch.Size([1, 128])\n",
      "Example Embedding (first 10 values): tensor([ 0.0521, -0.0629, -0.1503, -0.0279,  0.0409,  0.0786, -0.0517,  0.0373,\n",
      "         0.0544,  0.0284], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ------------------------------\n",
    "# CNN Module (Structural Patterns)\n",
    "# ------------------------------\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self, input_channels=1, embedding_dim=128):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Input: 2D distance/contact matrix from AlphaFold (e.g., 64x64)\n",
    "        Output: Embedding vector representing structural context\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # global average pooling\n",
    "\n",
    "        self.fc = nn.Linear(128, embedding_dim)  # final embedding vector\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 1, H, W]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.global_pool(x)  # shape  [batch, 128, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # shape  [batch, 128]\n",
    "\n",
    "        embedding = self.fc(x)\n",
    "        return embedding\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Example usage\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulate AlphaFold contact matrix (batch_size=1, 64x64)\n",
    "    contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "\n",
    "    model = StructuralCNN(input_channels=1, embedding_dim=128)\n",
    "    embedding = model(contact_matrix)\n",
    "\n",
    "    print(\"Structural Embedding Vector Shape:\", embedding.shape)\n",
    "    print(\"Example Embedding (first 10 values):\", embedding[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "654384bd-7490-4c5c-8b9d-de306dc285ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GCNConv, global_mean_pool\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# GNN Module (Graph Representation)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mStructuralGNN\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "# ------------------------------\n",
    "# GNN Module (Graph Representation)\n",
    "# ------------------------------\n",
    "class StructuralGNN(nn.Module):\n",
    "    def __init__(self, node_in_dim=128, hidden_dim=128, embedding_dim=128):\n",
    "        super(StructuralGNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Input: Graph representation of protein (nodes = residues)\n",
    "        Output: Graph-level embedding (structural + relational context)\n",
    "        \"\"\"\n",
    "        self.conv1 = GCNConv(node_in_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \"\"\"\n",
    "        x: [num_nodes, node_in_dim] node features (from CNN or sequence embedding)\n",
    "        edge_index: [2, num_edges] connectivity between nodes\n",
    "        batch: [num_nodes] batch vector to group nodes per protein\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "\n",
    "        # Graph-level pooling (mean over all node embeddings)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79735081-34eb-4fb0-b1f7-1d5be1ca85f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d81b9536-3625-4e6a-bf1a-dd0ee9278511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch-geometric\n",
      "  Using cached torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.11.10)\n",
      "Requirement already satisfied: fsspec in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
      "Collecting xxhash (from torch-geometric)\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.18.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2025.10.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\muska\\anaconda3\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Using cached torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Installing collected packages: xxhash, torch-geometric\n",
      "\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   -------------------- ------------------- 1/2 [torch-geometric]\n",
      "   ---------------------------------------- 2/2 [torch-geometric]\n",
      "\n",
      "Successfully installed torch-geometric-2.7.0 xxhash-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch-geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abc52b3-1e88-45a3-a140-fbe0079c3cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.9.0+cpu.html\n",
      "Collecting torch-scatter\n",
      "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-sparse\n",
      "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-sparse) (1.15.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.11.10)\n",
      "Requirement already satisfied: fsspec in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
      "Collecting xxhash (from torch-geometric)\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.18.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2025.10.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\muska\\anaconda3\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.3 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.5/1.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.8/1.3 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.0/1.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Building wheels for collected packages: torch-scatter, torch-sparse\n",
      "  Building wheel for torch-scatter (setup.py): started\n",
      "  Building wheel for torch-scatter (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for torch-scatter\n",
      "  Building wheel for torch-sparse (setup.py): started\n",
      "  Building wheel for torch-sparse (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for torch-sparse\n",
      "Failed to build torch-scatter torch-sparse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'torch-scatter' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'torch-scatter'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [32 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-313\n",
      "  creating build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\placeholder.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\scatter.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\segment_coo.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\segment_csr.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\testing.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\utils.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\__init__.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  creating build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\logsumexp.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\softmax.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\std.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\__init__.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  running egg_info\n",
      "  writing torch_scatter.egg-info\\PKG-INFO\n",
      "  writing dependency_links to torch_scatter.egg-info\\dependency_links.txt\n",
      "  writing requirements to torch_scatter.egg-info\\requires.txt\n",
      "  writing top-level names to torch_scatter.egg-info\\top_level.txt\n",
      "  reading manifest file 'torch_scatter.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*' found under directory 'test'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'torch_scatter.egg-info\\SOURCES.txt'\n",
      "  running build_ext\n",
      "  W1102 14:39:25.280000 28328 site-packages\\torch\\utils\\cpp_extension.py:480] Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "  building 'torch_scatter._scatter_cpu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for torch-scatter\n",
      "  DEPRECATION: Building 'torch-sparse' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'torch-sparse'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [56 lines of output]\n",
      "  running bdist_wheel\n",
      "  W1102 14:39:36.250000 25720 site-packages\\torch\\utils\\cpp_extension.py:630] Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-313\n",
      "  creating build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\add.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\bandwidth.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\cat.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\coalesce.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\convert.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\diag.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\eye.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\index_select.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\masked_select.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\matmul.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\metis.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\mul.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\narrow.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\permute.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\reduce.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\rw.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\saint.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\sample.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\select.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\spadd.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\spmm.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\spspmm.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\storage.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\tensor.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\testing.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\transpose.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\typing.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\utils.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\__init__.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  running egg_info\n",
      "  writing torch_sparse.egg-info\\PKG-INFO\n",
      "  writing dependency_links to torch_sparse.egg-info\\dependency_links.txt\n",
      "  writing requirements to torch_sparse.egg-info\\requires.txt\n",
      "  writing top-level names to torch_sparse.egg-info\\top_level.txt\n",
      "  reading manifest file 'torch_sparse.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\css'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\html'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\tests'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\examples'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\benchmark'\n",
      "  warning: no previously-included files matching '*' found under directory 'test'\n",
      "  warning: no previously-included files matching '*' found under directory 'benchmark'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'torch_sparse.egg-info\\SOURCES.txt'\n",
      "  running build_ext\n",
      "  W1102 14:39:37.341000 25720 site-packages\\torch\\utils\\cpp_extension.py:480] Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "  building 'torch_sparse._convert_cpu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for torch-sparse\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (torch-scatter, torch-sparse)\n",
      "WARNING: Skipping torch-scatter as it is not installed.\n",
      "WARNING: Skipping torch-sparse as it is not installed.\n",
      "WARNING: Skipping torch-geometric as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.9.0+cpu.html\n",
    "\n",
    "!pip uninstall -y torch-scatter torch-sparse torch-geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75112454-23cf-4f1f-957a-4448334ec2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.9.0+cpu.html\n",
      "Collecting torch-scatter\n",
      "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-sparse\n",
      "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-geometric\n",
      "  Using cached torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-sparse) (1.15.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.11.10)\n",
      "Requirement already satisfied: fsspec in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
      "Collecting xxhash (from torch-geometric)\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.18.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2025.10.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\muska\\anaconda3\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Using cached torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Building wheels for collected packages: torch-scatter, torch-sparse\n",
      "  Building wheel for torch-scatter (setup.py): started\n",
      "  Building wheel for torch-scatter (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for torch-scatter\n",
      "  Building wheel for torch-sparse (setup.py): started\n",
      "  Building wheel for torch-sparse (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for torch-sparse\n",
      "Failed to build torch-scatter torch-sparse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'torch-scatter' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'torch-scatter'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [32 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-313\n",
      "  creating build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\placeholder.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\scatter.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\segment_coo.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\segment_csr.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\testing.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\utils.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\__init__.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  creating build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\logsumexp.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\softmax.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\std.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\__init__.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  running egg_info\n",
      "  writing torch_scatter.egg-info\\PKG-INFO\n",
      "  writing dependency_links to torch_scatter.egg-info\\dependency_links.txt\n",
      "  writing requirements to torch_scatter.egg-info\\requires.txt\n",
      "  writing top-level names to torch_scatter.egg-info\\top_level.txt\n",
      "  reading manifest file 'torch_scatter.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*' found under directory 'test'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'torch_scatter.egg-info\\SOURCES.txt'\n",
      "  running build_ext\n",
      "  W1102 14:45:22.859000 21512 site-packages\\torch\\utils\\cpp_extension.py:480] Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "  building 'torch_scatter._scatter_cpu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for torch-scatter\n",
      "  DEPRECATION: Building 'torch-sparse' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'torch-sparse'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [56 lines of output]\n",
      "  running bdist_wheel\n",
      "  W1102 14:45:31.014000 17348 site-packages\\torch\\utils\\cpp_extension.py:630] Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-313\n",
      "  creating build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\add.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\bandwidth.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\cat.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\coalesce.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\convert.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\diag.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\eye.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\index_select.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\masked_select.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\matmul.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\metis.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\mul.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\narrow.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\permute.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\reduce.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\rw.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\saint.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\sample.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\select.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\spadd.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\spmm.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\spspmm.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\storage.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\tensor.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\testing.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\transpose.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\typing.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\utils.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\__init__.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  running egg_info\n",
      "  writing torch_sparse.egg-info\\PKG-INFO\n",
      "  writing dependency_links to torch_sparse.egg-info\\dependency_links.txt\n",
      "  writing requirements to torch_sparse.egg-info\\requires.txt\n",
      "  writing top-level names to torch_sparse.egg-info\\top_level.txt\n",
      "  reading manifest file 'torch_sparse.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\css'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\html'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\tests'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\examples'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\benchmark'\n",
      "  warning: no previously-included files matching '*' found under directory 'test'\n",
      "  warning: no previously-included files matching '*' found under directory 'benchmark'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'torch_sparse.egg-info\\SOURCES.txt'\n",
      "  running build_ext\n",
      "  W1102 14:45:31.556000 17348 site-packages\\torch\\utils\\cpp_extension.py:480] Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "  building 'torch_sparse._convert_cpu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for torch-sparse\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (torch-scatter, torch-sparse)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://data.pyg.org/whl/torch-2.9.0+cpu.html\n",
      "Collecting torch-scatter\n",
      "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-sparse\n",
      "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torch-geometric\n",
      "  Using cached torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-sparse) (1.15.3)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.11.10)\n",
      "Requirement already satisfied: fsspec in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2.1.3)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
      "Collecting xxhash (from torch-geometric)\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from aiohttp->torch-geometric) (1.18.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->torch-geometric) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->torch-geometric) (2025.10.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\muska\\anaconda3\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Using cached torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Building wheels for collected packages: torch-scatter, torch-sparse\n",
      "  Building wheel for torch-scatter (setup.py): started\n",
      "  Building wheel for torch-scatter (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for torch-scatter\n",
      "  Building wheel for torch-sparse (setup.py): started\n",
      "  Building wheel for torch-sparse (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for torch-sparse\n",
      "Failed to build torch-scatter torch-sparse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'torch-scatter' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'torch-scatter'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [32 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-313\n",
      "  creating build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\placeholder.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\scatter.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\segment_coo.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\segment_csr.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\testing.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\utils.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  copying torch_scatter\\__init__.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\n",
      "  creating build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\logsumexp.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\softmax.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\std.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  copying torch_scatter\\composite\\__init__.py -> build\\lib.win-amd64-cpython-313\\torch_scatter\\composite\n",
      "  running egg_info\n",
      "  writing torch_scatter.egg-info\\PKG-INFO\n",
      "  writing dependency_links to torch_scatter.egg-info\\dependency_links.txt\n",
      "  writing requirements to torch_scatter.egg-info\\requires.txt\n",
      "  writing top-level names to torch_scatter.egg-info\\top_level.txt\n",
      "  reading manifest file 'torch_scatter.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*' found under directory 'test'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'torch_scatter.egg-info\\SOURCES.txt'\n",
      "  running build_ext\n",
      "  W1102 14:45:57.249000 22744 site-packages\\torch\\utils\\cpp_extension.py:480] Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "  building 'torch_scatter._scatter_cpu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for torch-scatter\n",
      "  DEPRECATION: Building 'torch-sparse' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'torch-sparse'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [56 lines of output]\n",
      "  running bdist_wheel\n",
      "  W1102 14:46:05.589000 25092 site-packages\\torch\\utils\\cpp_extension.py:630] Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-313\n",
      "  creating build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\add.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\bandwidth.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\cat.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\coalesce.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\convert.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\diag.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\eye.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\index_select.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\masked_select.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\matmul.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\metis.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\mul.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\narrow.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\permute.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\reduce.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\rw.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\saint.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\sample.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\select.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\spadd.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\spmm.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\spspmm.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\storage.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\tensor.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\testing.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\transpose.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\typing.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\utils.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  copying torch_sparse\\__init__.py -> build\\lib.win-amd64-cpython-313\\torch_sparse\n",
      "  running egg_info\n",
      "  writing torch_sparse.egg-info\\PKG-INFO\n",
      "  writing dependency_links to torch_sparse.egg-info\\dependency_links.txt\n",
      "  writing requirements to torch_sparse.egg-info\\requires.txt\n",
      "  writing top-level names to torch_sparse.egg-info\\top_level.txt\n",
      "  reading manifest file 'torch_sparse.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\css'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\html'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\tests'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\examples'\n",
      "  warning: no previously-included files matching '*' found under directory 'third_party\\parallel-hashmap\\benchmark'\n",
      "  warning: no previously-included files matching '*' found under directory 'test'\n",
      "  warning: no previously-included files matching '*' found under directory 'benchmark'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'torch_sparse.egg-info\\SOURCES.txt'\n",
      "  running build_ext\n",
      "  W1102 14:46:06.355000 25092 site-packages\\torch\\utils\\cpp_extension.py:480] Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "  building 'torch_sparse._convert_cpu' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for torch-sparse\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (torch-scatter, torch-sparse)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.9.0+cpu.html\n",
    "!pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.9.0+cpu.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33a09096-5e2c-480a-af29-b7c682d81fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PyTorch Geometric is ready to use!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "print(\" PyTorch Geometric is ready to use!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3f89dff-a6be-4b17-b3e8-363a61aff304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "# ------------------------------\n",
    "# GNN Module (Graph Representation)\n",
    "# ------------------------------\n",
    "class StructuralGNN(nn.Module):\n",
    "    def __init__(self, node_in_dim=128, hidden_dim=128, embedding_dim=128):\n",
    "        super(StructuralGNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Input: Graph representation of protein (nodes = residues)\n",
    "        Output: Graph-level embedding (structural + relational context)\n",
    "        \"\"\"\n",
    "        self.conv1 = GCNConv(node_in_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \"\"\"\n",
    "        x: [num_nodes, node_in_dim] node features (from CNN or sequence embedding)\n",
    "        edge_index: [2, num_edges] connectivity between nodes\n",
    "        batch: [num_nodes] batch vector to group nodes per protein\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "\n",
    "        # Graph-level pooling (mean over all node embeddings)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046946b-e563-43fd-a691-2c6d135776d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8b440be-dbb3-42e8-b825-909e8c7beba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ------------------------------\n",
    "# Transformer Module (Sequence Context)\n",
    "# ------------------------------\n",
    "class SequenceTransformer(nn.Module):\n",
    "    def __init__(self, seq_len=512, embed_dim=128, num_heads=8, num_layers=2, dropout=0.1):\n",
    "        super(SequenceTransformer, self).__init__()\n",
    "        \"\"\"\n",
    "        Input: Sequence embeddings + positional encoding (variant position)\n",
    "        Output: Embedding vector representing sequence context\n",
    "        \"\"\"\n",
    "\n",
    "        # Positional encoding (learnable)\n",
    "        self.pos_embedding = nn.Embedding(seq_len, embed_dim)\n",
    "\n",
    "        # Transformer Encoder layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dim_feedforward=256,\n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Final sequence embedding projection\n",
    "        self.fc = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, seq_embeddings, variant_pos=None):\n",
    "        \"\"\"\n",
    "        seq_embeddings: [batch, seq_len, embed_dim]\n",
    "        variant_pos: list/tensor of variant positions (optional)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len, _ = seq_embeddings.size()\n",
    "\n",
    "        # Add positional encoding\n",
    "        positions = torch.arange(seq_len, device=seq_embeddings.device).unsqueeze(0)\n",
    "        pos_emb = self.pos_embedding(positions)\n",
    "        x = seq_embeddings + pos_emb\n",
    "\n",
    "        # Pass through Transformer Encoder\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # If variant position provided, extract its context vector\n",
    "        if variant_pos is not None:\n",
    "            idx = variant_pos.long().unsqueeze(-1).unsqueeze(-1).expand(-1, 1, x.size(-1))\n",
    "            variant_emb = torch.gather(x, 1, idx).squeeze(1)\n",
    "        else:\n",
    "            # Global average pooling if variant position not given\n",
    "            variant_emb = x.mean(dim=1)\n",
    "\n",
    "        out = self.fc(variant_emb)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbc67930-f40f-48a5-89b0-13294914fccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN Structural Embedding Shape: torch.Size([1, 128])\n",
      "Graph-level Embedding: tensor([[-1.1701e-01,  3.3949e-01,  3.3200e-01, -1.6349e-02, -1.1113e-01,\n",
      "          9.5515e-02, -7.8390e-03, -1.7458e-01, -1.3772e-01, -2.2421e-01,\n",
      "          2.0224e-01, -9.4489e-02,  1.9384e-01,  7.5994e-02, -1.8465e-01,\n",
      "          9.4791e-03, -1.1883e-01, -1.2106e-01,  2.1763e-05,  1.1804e-01,\n",
      "          3.4863e-01,  1.5225e-01,  1.4202e-02, -2.3250e-01, -2.8812e-01,\n",
      "         -1.8030e-01,  1.6206e-01,  1.3166e-01,  4.6108e-02, -1.8608e-01,\n",
      "          1.1743e-01,  1.1736e-01,  7.7772e-02,  1.6215e-01, -9.7333e-03,\n",
      "          1.2260e-01, -2.3181e-02, -1.1576e-01,  8.9787e-02,  4.4712e-02,\n",
      "          3.4639e-02,  1.0141e-01,  9.3240e-02,  8.5480e-02, -1.2755e-01,\n",
      "          1.9587e-01, -1.1118e-01, -3.3523e-01, -2.0722e-02,  2.6581e-01,\n",
      "         -8.5945e-02,  1.1450e-01,  6.3505e-02,  1.3858e-01, -2.1607e-02,\n",
      "          2.5020e-01,  4.5125e-02,  7.5419e-02, -4.7158e-02, -1.0258e-01,\n",
      "          9.9375e-02,  1.0669e-02,  1.8400e-02, -1.5782e-01, -2.4949e-01,\n",
      "          1.9381e-01, -9.1626e-02,  3.1171e-02, -8.0224e-02, -3.4865e-01,\n",
      "         -1.2390e-01,  1.0123e-01,  2.5883e-02, -9.5285e-02,  8.0538e-02,\n",
      "          1.0247e-01, -4.8129e-02,  1.2760e-01,  5.8030e-02,  3.7147e-02,\n",
      "          2.5259e-01, -1.7235e-01, -1.6056e-01,  8.9492e-02, -6.3089e-02,\n",
      "         -7.1649e-04,  1.5363e-01,  6.0753e-02, -8.1248e-02, -1.8657e-02,\n",
      "         -6.6180e-02, -2.1729e-01,  8.4931e-02,  6.7349e-02,  1.4076e-01,\n",
      "          2.1226e-01,  7.9398e-02, -1.0427e-01,  8.8170e-02,  1.2009e-02,\n",
      "         -1.6195e-01, -2.2343e-01, -1.0038e-01,  2.5526e-02,  1.5023e-01,\n",
      "         -2.8270e-02, -1.2960e-01,  2.6706e-01,  3.4674e-01, -4.1062e-02,\n",
      "         -8.2633e-02,  9.2871e-02, -9.8129e-02, -7.9218e-02, -5.7825e-02,\n",
      "         -8.6368e-02,  5.6217e-02, -1.2386e-01, -8.0169e-02,  2.7275e-01,\n",
      "          1.8650e-02, -5.8019e-02, -1.2783e-01,  2.8358e-02, -2.6659e-02,\n",
      "         -1.5722e-01, -8.3620e-02, -4.3669e-03]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Assume from previous CNN code:\n",
    "# cnn_model = StructuralCNN()\n",
    "# contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "cnn_embedding = cnn_model(contact_matrix)  # shape: [1, 128]\n",
    "\n",
    "# Suppose each residue is represented by CNN embedding\n",
    "# For simplicity, simulate 50 residues  50 nodes, each 128-dim feature\n",
    "num_residues = 50\n",
    "x = torch.rand(num_residues, 128)\n",
    "\n",
    "# Define dummy edges (simple chain or contact-based)\n",
    "edge_index = torch.tensor([\n",
    "    [i for i in range(num_residues - 1)] + [i + 1 for i in range(num_residues - 1)],\n",
    "    [i + 1 for i in range(num_residues - 1)] + [i for i in range(num_residues - 1)]\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Batch info (1 graph  all nodes belong to same protein)\n",
    "batch = torch.zeros(num_residues, dtype=torch.long)\n",
    "\n",
    "# Run GNN\n",
    "gnn_model = StructuralGNN(node_in_dim=128)\n",
    "gnn_embedding = gnn_model(x, edge_index, batch)\n",
    "\n",
    "print(\"GNN Structural Embedding Shape:\", gnn_embedding.shape)\n",
    "print(\"Graph-level Embedding:\", gnn_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41030067-c8e2-4bef-9533-9a61a167efd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN embedding shape: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ------------------------------\n",
    "# CNN Module (Structural Patterns)\n",
    "# ------------------------------\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, 128)  # assuming input 6464\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize CNN model\n",
    "cnn_model = StructuralCNN()\n",
    "\n",
    "# Example input (6464 contact matrix)\n",
    "contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "\n",
    "# Get CNN embedding\n",
    "cnn_embedding = cnn_model(contact_matrix)\n",
    "print(\"CNN embedding shape:\", cnn_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f627ade6-dd02-491f-affc-fdf069b42771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Context Embedding Shape: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# Simulated amino acid sequence embeddings (batch=1, seq_len=100, embed_dim=128)\n",
    "seq_embeddings = torch.rand(1, 100, 128)\n",
    "\n",
    "# Variant at position 45\n",
    "variant_position = torch.tensor([45])\n",
    "\n",
    "model = SequenceTransformer(seq_len=100, embed_dim=128)\n",
    "seq_context_emb = model(seq_embeddings, variant_position)\n",
    "\n",
    "print(\"Sequence Context Embedding Shape:\", seq_context_emb.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af452728-ea7a-43d7-9285-166f1b426e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assume you already defined:\n",
    "# - StructuralCNN\n",
    "# - StructuralGNN\n",
    "# - SequenceTransformer\n",
    "\n",
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self, seq_len=512, embed_dim=128, num_classes=2):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "\n",
    "        # --- Individual Modules ---\n",
    "        self.cnn_module = StructuralCNN(input_channels=1, embedding_dim=embed_dim)\n",
    "        self.gnn_module = StructuralGNN(node_in_dim=embed_dim, hidden_dim=128, embedding_dim=embed_dim)\n",
    "        self.seq_module = SequenceTransformer(seq_len=seq_len, embed_dim=embed_dim)\n",
    "\n",
    "        # --- Fusion Layer ---\n",
    "        self.fc_fusion = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # --- Output Prediction Head ---\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, contact_matrix, residue_graph, seq_embeddings, variant_pos=None):\n",
    "        \"\"\"\n",
    "        contact_matrix: [B, 1, H, W]   -> CNN\n",
    "        residue_graph: tuple(x, edge_index, batch) -> GNN\n",
    "        seq_embeddings: [B, seq_len, embed_dim]    -> Transformer\n",
    "        \"\"\"\n",
    "\n",
    "        # CNN output  local structure\n",
    "        cnn_out = self.cnn_module(contact_matrix)\n",
    "\n",
    "        # GNN output  global structure\n",
    "        x, edge_index, batch = residue_graph\n",
    "        gnn_out = self.gnn_module(x, edge_index, batch)\n",
    "\n",
    "        # Transformer output  sequence context\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)\n",
    "\n",
    "        # Combine embeddings (concatenate)\n",
    "        combined = torch.cat([cnn_out, gnn_out, seq_out], dim=-1)\n",
    "\n",
    "        # Fusion and classification\n",
    "        fused = self.fc_fusion(combined)\n",
    "        logits = self.classifier(fused)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aeaf40b7-5a39-4c19-b405-b1211aa2a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0067, 0.0694]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self, input_channels=1, embedding_dim=128):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Input: 2D contact/distance matrix (AlphaFold)\n",
    "        Output: Embedding vector representing structural context\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.fc = nn.Linear(128, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.global_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "model = HybridVariantPredictor(seq_len=100, embed_dim=128, num_classes=2)\n",
    "output = model(contact_matrix, residue_graph, seq_embeddings, variant_pos)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7524efec-1952-4926-9d3c-29adeb50393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.6879 - Accuracy: 0.5000\n",
      "Epoch [2/5] - Loss: 0.6833 - Accuracy: 0.7500\n",
      "Epoch [3/5] - Loss: 0.6741 - Accuracy: 1.0000\n",
      "Epoch [4/5] - Loss: 0.6632 - Accuracy: 1.0000\n",
      "Epoch [5/5] - Loss: 0.6487 - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Initialize model\n",
    "model = HybridVariantPredictor(seq_len=100, embed_dim=128, num_classes=2)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()       # good for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "# Example: simulate a batch of 4 samples\n",
    "batch_size = 4\n",
    "\n",
    "contact_matrices = torch.rand(batch_size, 1, 64, 64)\n",
    "num_residues = 50\n",
    "seq_len = 100\n",
    "variant_positions = torch.randint(0, seq_len, (batch_size,))\n",
    "\n",
    "# Each sample  different graph\n",
    "x = torch.rand(num_residues * batch_size, 128)\n",
    "edge_index = torch.tensor([\n",
    "    [i for i in range(num_residues - 1)] * batch_size + [i + 1 for i in range(num_residues - 1)] * batch_size,\n",
    "    [i + 1 for i in range(num_residues - 1)] * batch_size + [i for i in range(num_residues - 1)] * batch_size\n",
    "], dtype=torch.long)\n",
    "batch = torch.repeat_interleave(torch.arange(batch_size), num_residues)\n",
    "\n",
    "residue_graph = (x, edge_index, batch)\n",
    "\n",
    "seq_embeddings = torch.rand(batch_size, seq_len, 128)\n",
    "labels = torch.randint(0, 2, (batch_size,))  # 0=benign, 1=pathogenic\n",
    "epochs = 5  # increase later\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(contact_matrices, residue_graph, seq_embeddings, variant_positions)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Accuracy\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "    acc = (preds == labels).float().mean()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {loss.item():.4f} - Accuracy: {acc.item():.4f}\")\n",
    "torch.save(model.state_dict(), \"hybrid_variant_predictor.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3765e58-a5b5-45aa-8344-052d6d1bde2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Name       Gene(s)  \\\n",
      "0  NM_001709.5(BDNF):c.715T>G (p.Cys239Gly)  BDNF|BDNF-AS   \n",
      "1  NM_001709.5(BDNF):c.715T>G (p.Cys239Gly)  BDNF|BDNF-AS   \n",
      "2  NM_001709.5(BDNF):c.715T>G (p.Cys239Gly)  BDNF|BDNF-AS   \n",
      "3  NM_001709.5(BDNF):c.715T>G (p.Cys239Gly)  BDNF|BDNF-AS   \n",
      "4  NM_001709.5(BDNF):c.715T>G (p.Cys239Gly)  BDNF|BDNF-AS   \n",
      "\n",
      "                      Protein change           Condition(s)     Accession  \\\n",
      "0  C239G, C247G, C254G, C268G, C321G  BDNF-related disorder  VCV003344608   \n",
      "1  C239G, C247G, C254G, C268G, C321G  BDNF-related disorder  VCV003344608   \n",
      "2  C239G, C247G, C254G, C268G, C321G  BDNF-related disorder  VCV003344608   \n",
      "3  C239G, C247G, C254G, C268G, C321G  BDNF-related disorder  VCV003344608   \n",
      "4  C239G, C247G, C254G, C268G, C321G  BDNF-related disorder  VCV003344608   \n",
      "\n",
      "   GRCh37Chromosome  GRCh37Location  GRCh38Chromosome  GRCh38Location  \\\n",
      "0                11        27679397                11        27657850   \n",
      "1                11        27679397                11        27657850   \n",
      "2                11        27679397                11        27657850   \n",
      "3                11        27679397                11        27657850   \n",
      "4                11        27679397                11        27657850   \n",
      "\n",
      "   VariationID  ...  Oncogenicity review status VariantType Orig_AA Residue  \\\n",
      "0      3344608  ...                         NaN    missense       C   239.0   \n",
      "1      3344608  ...                         NaN    missense       C   247.0   \n",
      "2      3344608  ...                         NaN    missense       C   254.0   \n",
      "3      3344608  ...                         NaN    missense       C   268.0   \n",
      "4      3344608  ...                         NaN    missense       C   321.0   \n",
      "\n",
      "  New_AA                                             Parsed        Region  \\\n",
      "0      G  [('C', '239', 'G'), ('C', '247', 'G'), ('C', '...        mature   \n",
      "1      G  [('C', '239', 'G'), ('C', '247', 'G'), ('C', '...        mature   \n",
      "2      G  [('C', '239', 'G'), ('C', '247', 'G'), ('C', '...  out_of_range   \n",
      "3      G  [('C', '239', 'G'), ('C', '247', 'G'), ('C', '...  out_of_range   \n",
      "4      G  [('C', '239', 'G'), ('C', '247', 'G'), ('C', '...  out_of_range   \n",
      "\n",
      "  Mature_pos         Mapping  Truncation_length  \n",
      "0      111.0           C239G                NaN  \n",
      "1      119.0  Mismatch(R->C)                NaN  \n",
      "2        NaN    Out_of_range                NaN  \n",
      "3        NaN    Out_of_range                NaN  \n",
      "4        NaN    Out_of_range                NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Index(['Name', 'Gene(s)', 'Protein change', 'Condition(s)', 'Accession',\n",
      "       'GRCh37Chromosome', 'GRCh37Location', 'GRCh38Chromosome',\n",
      "       'GRCh38Location', 'VariationID', 'AlleleID(s)', 'dbSNP ID',\n",
      "       'Canonical SPDI', 'Variant type', 'Molecular consequence',\n",
      "       'Germline classification', 'Germline date last evaluated',\n",
      "       'Germline review status', 'Somatic clinical impact',\n",
      "       'Somatic clinical impact date last evaluated',\n",
      "       'Somatic clinical impact review status', 'Oncogenicity classification',\n",
      "       'Oncogenicity date last evaluated', 'Oncogenicity review status',\n",
      "       'VariantType', 'Orig_AA', 'Residue', 'New_AA', 'Parsed', 'Region',\n",
      "       'Mature_pos', 'Mapping', 'Truncation_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file (replace the filename with your actual one)\n",
    "df = pd.read_csv(\"E:/vit/ai/data/BDNF_missense_expanded_mapped.csv\")\n",
    "\n",
    "# Preview dataset\n",
    "print(df.head())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5595afd3-ac6e-41dc-a68f-f7f9f7653765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processed 21 valid variants for modeling.\n",
      "    Residue Orig_AA New_AA  label\n",
      "30      186       C      Y      1\n",
      "31      194       C      Y      1\n",
      "32      201       C      Y      1\n",
      "33      215       C      Y      1\n",
      "34      268       C      Y      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"E:/vit/ai/data/BDNF_missense_expanded_mapped.csv\")\n",
    "\n",
    "# Step 1: Filter missense variants\n",
    "df = df[df[\"VariantType\"].str.lower() == \"missense\"].copy()\n",
    "\n",
    "# Step 2: Drop rows without residue positions or labels\n",
    "df = df.dropna(subset=[\"Residue\"])\n",
    "\n",
    "# Step 3: Convert residue positions to integers\n",
    "df[\"Residue\"] = df[\"Residue\"].astype(int)\n",
    "\n",
    "# Step 4: Encode labels\n",
    "# Try to use 'Germline classification' or 'Oncogenicity classification' if available\n",
    "if \"Germline classification\" in df.columns:\n",
    "    label_col = \"Germline classification\"\n",
    "elif \"Oncogenicity classification\" in df.columns:\n",
    "    label_col = \"Oncogenicity classification\"\n",
    "else:\n",
    "    raise ValueError(\"No pathogenicity label found in CSV\")\n",
    "\n",
    "# Simplify to binary labels\n",
    "def encode_label(val):\n",
    "    if isinstance(val, str):\n",
    "        val = val.lower()\n",
    "        if \"pathogenic\" in val:\n",
    "            return 1\n",
    "        elif \"benign\" in val:\n",
    "            return 0\n",
    "    return None\n",
    "\n",
    "df[\"label\"] = df[label_col].apply(encode_label)\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "print(f\" Processed {len(df)} valid variants for modeling.\")\n",
    "print(df[[\"Residue\", \"Orig_AA\", \"New_AA\", \"label\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a06203e7-89a7-4b3c-b25a-49503b6d98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model output: tensor([[0.5051]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "\n",
    "# ------------------------------\n",
    "# 1. CNN Module (Structural Patterns)\n",
    "# ------------------------------\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, 128)  # for input 64x64\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x  # [batch, 128]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Simplified GNN (Manual message passing)\n",
    "# ------------------------------\n",
    "class SimpleGNN(nn.Module):\n",
    "    def __init__(self, in_features=128, hidden_dim=64, out_features=64):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_features)\n",
    "\n",
    "    def forward(self, features, adj):\n",
    "        h = torch.matmul(adj, features)  # aggregate neighbors\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = torch.matmul(adj, h)\n",
    "        h = self.fc2(h)\n",
    "        return h.mean(dim=0)  # global mean pooling [64]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Transformer (Sequence Context)\n",
    "# ------------------------------\n",
    "class SequenceTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=128, nhead=4, hidden_dim=256, num_layers=2):\n",
    "        super(SequenceTransformer, self).__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim, nhead=nhead, dim_feedforward=hidden_dim, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, seq_embeddings, variant_pos=None):\n",
    "        x = self.transformer(seq_embeddings)  # [batch, seq_len, embed_dim]\n",
    "        if variant_pos is not None:\n",
    "            seq_len = x.size(1)\n",
    "            variant_pos = torch.clamp(variant_pos, max=seq_len - 1)\n",
    "            idx = variant_pos.long().unsqueeze(-1).unsqueeze(-1).expand(-1, 1, x.size(-1))\n",
    "            variant_emb = torch.gather(x, 1, idx).squeeze(1)\n",
    "        else:\n",
    "            variant_emb = x.mean(dim=1)\n",
    "        return variant_emb  # [batch, embed_dim]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Hybrid Model (CNN + GNN + Transformer)\n",
    "# ------------------------------\n",
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "        self.cnn_module = StructuralCNN()\n",
    "        self.gnn_module = SimpleGNN()\n",
    "        self.seq_module = SequenceTransformer(input_dim=128)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 64 + 128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, contact_matrix, adj, seq_embeddings, variant_pos):\n",
    "        cnn_out = self.cnn_module(contact_matrix)       # [1,128]\n",
    "        node_features = cnn_out.repeat(adj.size(0), 1)  # replicate to [num_nodes,128]\n",
    "        gnn_out = self.gnn_module(node_features, adj)   # [64]\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)  # [1,128]\n",
    "        combined = torch.cat([cnn_out.squeeze(0), gnn_out, seq_out.squeeze(0)], dim=-1)\n",
    "        return self.classifier(combined.unsqueeze(0))   # [1,1]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Test Run with Dummy Data\n",
    "# ------------------------------\n",
    "contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "num_nodes = 50\n",
    "G = nx.erdos_renyi_graph(num_nodes, 0.1)\n",
    "adj = torch.tensor(nx.to_numpy_array(G), dtype=torch.float32)\n",
    "seq_embeddings = torch.rand(1, 100, 128)\n",
    "variant_pos = torch.tensor([186])  # intentionally out of bounds\n",
    "\n",
    "# Initialize model\n",
    "model = HybridVariantPredictor()\n",
    "output = model(contact_matrix, adj, seq_embeddings, variant_pos)\n",
    "print(\" Model output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e85efbe-db16-4377-b1ee-101ce04ef600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model output: tensor([[0.5054]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "\n",
    "# ------------------------------\n",
    "# 1. CNN Module (Structural Patterns)\n",
    "# ------------------------------\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, 128)  # for input 64x64\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x  # [batch, 128]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Simplified GNN (Manual message passing)\n",
    "# ------------------------------\n",
    "class SimpleGNN(nn.Module):\n",
    "    def __init__(self, in_features=128, hidden_dim=64, out_features=64):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_features)\n",
    "\n",
    "    def forward(self, features, adj):\n",
    "        h = torch.matmul(adj, features)  # aggregate neighbors\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = torch.matmul(adj, h)\n",
    "        h = self.fc2(h)\n",
    "        return h.mean(dim=0)  # global mean pooling [64]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Transformer (Sequence Context)\n",
    "# ------------------------------\n",
    "class SequenceTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=128, nhead=4, hidden_dim=256, num_layers=2):\n",
    "        super(SequenceTransformer, self).__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim, nhead=nhead, dim_feedforward=hidden_dim, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, seq_embeddings, variant_pos=None):\n",
    "        x = self.transformer(seq_embeddings)  # [batch, seq_len, embed_dim]\n",
    "        if variant_pos is not None:\n",
    "            seq_len = x.size(1)\n",
    "            variant_pos = torch.clamp(variant_pos, max=seq_len - 1)\n",
    "            idx = variant_pos.long().unsqueeze(-1).unsqueeze(-1).expand(-1, 1, x.size(-1))\n",
    "            variant_emb = torch.gather(x, 1, idx).squeeze(1)\n",
    "        else:\n",
    "            variant_emb = x.mean(dim=1)\n",
    "        return variant_emb  # [batch, embed_dim]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Hybrid Model (CNN + GNN + Transformer)\n",
    "# ------------------------------\n",
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "        self.cnn_module = StructuralCNN()\n",
    "        self.gnn_module = SimpleGNN()\n",
    "        self.seq_module = SequenceTransformer(input_dim=128)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 64 + 128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, contact_matrix, adj, seq_embeddings, variant_pos):\n",
    "        cnn_out = self.cnn_module(contact_matrix)       # [1,128]\n",
    "        node_features = cnn_out.repeat(adj.size(0), 1)  # replicate for nodes [num_nodes,128]\n",
    "        gnn_out = self.gnn_module(node_features, adj)   # [64]\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)  # [1,128]\n",
    "        combined = torch.cat([cnn_out.squeeze(0), gnn_out, seq_out.squeeze(0)], dim=-1)\n",
    "        return self.classifier(combined.unsqueeze(0))   # [1,1]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Test Run with Dummy Data\n",
    "# ------------------------------\n",
    "contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "num_nodes = 50\n",
    "G = nx.erdos_renyi_graph(num_nodes, 0.1)\n",
    "adj = torch.tensor(nx.to_numpy_array(G), dtype=torch.float32)\n",
    "seq_embeddings = torch.rand(1, 100, 128)\n",
    "variant_pos = torch.tensor([186])  # intentionally out of bounds\n",
    "\n",
    "# Initialize model\n",
    "model = HybridVariantPredictor()\n",
    "output = model(contact_matrix, adj, seq_embeddings, variant_pos)\n",
    "print(\" Model output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07fcb6cc-3c75-42d8-8694-0ecdf62d31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self, seq_len=100, embed_dim=128, num_classes=2, dropout=0.3):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "        self.cnn_module = StructuralCNN(embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.gnn_module = StructuralGNN(node_in_dim=embed_dim, embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.seq_module = SequenceTransformer(seq_len=seq_len, embed_dim=embed_dim, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(embed_dim * 3, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, contact_matrix, residue_graph, seq_embeddings, variant_pos):\n",
    "        cnn_out = self.cnn_module(contact_matrix)\n",
    "        gnn_out = self.gnn_module(residue_graph)\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)\n",
    "\n",
    "        combined = torch.cat((cnn_out, gnn_out, seq_out), dim=1)\n",
    "        x = F.relu(self.bn1(self.fc1(combined)))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=1e-4, \n",
    "    weight_decay=1e-5  #  L2 regularization\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d84a6a63-a7e7-4bcd-98e5-7a185f732934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model output shape: torch.Size([2])\n",
      " Output: tensor([-0.0141,  0.0672], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# =========================\n",
    "# 1. CNN Module\n",
    "# =========================\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, dropout=0.3):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(self.fc(x))\n",
    "        return x  # [batch, embedding_dim]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. GNN Module (Matrix-based)\n",
    "# =========================\n",
    "class StructuralGNN(nn.Module):\n",
    "    def __init__(self, node_in_dim=128, embedding_dim=128, dropout=0.3):\n",
    "        super(StructuralGNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(node_in_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, node_features, adj):\n",
    "        # node_features: [N, F]\n",
    "        # adj: [N, N]\n",
    "        h = torch.matmul(adj, node_features)\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = torch.matmul(adj, h)\n",
    "        h = self.dropout(F.relu(self.fc2(h)))\n",
    "        gnn_embedding = torch.mean(h, dim=0)  # graph-level embedding\n",
    "        return gnn_embedding  # [embedding_dim]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. Transformer Module\n",
    "# =========================\n",
    "class SequenceTransformer(nn.Module):\n",
    "    def __init__(self, seq_len=100, embed_dim=128, dropout=0.3):\n",
    "        super(SequenceTransformer, self).__init__()\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_len, embed_dim))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=8, dim_feedforward=256, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        self.fc = nn.Linear(embed_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, seq_embeddings, variant_pos):\n",
    "        # seq_embeddings: [batch, seq_len, embed_dim]\n",
    "        x = seq_embeddings + self.pos_embedding\n",
    "        x = self.transformer(x)\n",
    "        variant_token = x[:, variant_pos, :]  # extract variant position embedding\n",
    "        x = self.dropout(self.fc(variant_token))\n",
    "        return x  # [batch, embed_dim]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4. Hybrid Model\n",
    "# =========================\n",
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self, seq_len=100, embed_dim=128, num_classes=2, dropout=0.3):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "        self.cnn_module = StructuralCNN(embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.gnn_module = StructuralGNN(node_in_dim=embed_dim, embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.seq_module = SequenceTransformer(seq_len=seq_len, embed_dim=embed_dim, dropout=dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(embed_dim * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, contact_matrix, adj, seq_embeddings, variant_pos):\n",
    "        cnn_out = self.cnn_module(contact_matrix)  # [1, 128]\n",
    "        # For GNN, assume 50 nodes with same embedding dim as CNN output\n",
    "        node_features = torch.randn(50, cnn_out.shape[-1])\n",
    "        gnn_out = self.gnn_module(node_features, adj)  # [128]\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)  # [1, 128]\n",
    "\n",
    "        combined = torch.cat([cnn_out.squeeze(0), gnn_out, seq_out.squeeze(0)], dim=-1)\n",
    "        x = F.relu(self.fc1(combined))\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. Example Run\n",
    "# =========================\n",
    "seq_len = 100\n",
    "embed_dim = 128\n",
    "\n",
    "contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "adj = torch.eye(50)\n",
    "seq_embeddings = torch.rand(1, seq_len, embed_dim)\n",
    "variant_pos = 10\n",
    "\n",
    "model = HybridVariantPredictor(seq_len=seq_len, embed_dim=embed_dim, num_classes=2, dropout=0.3)\n",
    "output = model(contact_matrix, adj, seq_embeddings, variant_pos)\n",
    "\n",
    "print(\" Model output shape:\", output.shape)\n",
    "print(\" Output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c46aa7a9-60dc-408e-9b3b-029f08950139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded variants: 239\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m     29\u001b[0m model \u001b[38;5;241m=\u001b[39m HybridVariantPredictor(seq_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[0;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Run predictions\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:1484\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1482\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1484\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1486\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best_model.pth'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your variant CSV\n",
    "df = pd.read_csv(\"E:/vit/ai/data/BDNF_missense_expanded_mapped.csv\")\n",
    "\n",
    "# Focus on relevant columns\n",
    "variant_data = df[['Residue', 'Orig_AA', 'New_AA', 'Region', 'Protein change']]\n",
    "print(\"Loaded variants:\", len(variant_data))\n",
    "\n",
    "# Encode residue positions (dummy mapping for now)\n",
    "residues = torch.tensor(variant_data['Residue'].fillna(0).values, dtype=torch.long)\n",
    "\n",
    "# Dummy embeddings (in practice, youll replace these with sequence or structure encodings)\n",
    "num_variants = len(variant_data)\n",
    "contact_matrices = torch.randn(num_variants, 1, 64, 64)\n",
    "sequence_embeddings = torch.randn(num_variants, 100, 128)\n",
    "variant_positions = residues % 100  # map residue position to sequence window\n",
    "\n",
    "# Dummy graph data (replace later with graph embeddings from structure)\n",
    "graph_data = (\n",
    "    torch.randn(num_variants, 128),          # node features\n",
    "    torch.randint(0, num_variants, (2, num_variants)),  # edges\n",
    "    torch.zeros(num_variants, dtype=torch.long)          # batch indices\n",
    ")\n",
    "\n",
    "# Load the trained model\n",
    "model = HybridVariantPredictor(seq_len=100, embed_dim=128, num_classes=2)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "# Run predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(contact_matrices, graph_data, sequence_embeddings, variant_positions)\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "# Add predictions to dataframe\n",
    "variant_data['Predicted_Class'] = preds.numpy()\n",
    "variant_data['Pathogenic_Prob'] = probs[:, 1].numpy()\n",
    "\n",
    "# Display results\n",
    "print(variant_data.head())\n",
    "\n",
    "# Save the annotated file\n",
    "variant_data.to_csv(\"E:/vit/ai/data/BDNF_processed_with_predictions.csv\", index=False)\n",
    "print(\"\\n Predictions saved to 'BDNF_processed_with_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96c1f345-6b99-4bcf-b237-73ba266a71b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded variants: 239\n",
      " No pretrained model found  using untrained model weights.\n",
      "\n",
      " Predictions saved to 'BDNF_processed_with_predictions.csv'\n",
      "   Residue Orig_AA New_AA        Region                     Protein change  \\\n",
      "0    239.0       C      G        mature  C239G, C247G, C254G, C268G, C321G   \n",
      "1    247.0       C      G        mature  C239G, C247G, C254G, C268G, C321G   \n",
      "2    254.0       C      G  out_of_range  C239G, C247G, C254G, C268G, C321G   \n",
      "3    268.0       C      G  out_of_range  C239G, C247G, C254G, C268G, C321G   \n",
      "4    321.0       C      G  out_of_range  C239G, C247G, C254G, C268G, C321G   \n",
      "\n",
      "   Predicted_Class  Pathogenic_Prob  \n",
      "0                1         0.508206  \n",
      "1                0         0.489482  \n",
      "2                0         0.474495  \n",
      "3                0         0.468924  \n",
      "4                0         0.479513  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muska\\AppData\\Local\\Temp\\ipykernel_3916\\1037050491.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  variant_data['Predicted_Class'] = pred_classes\n",
      "C:\\Users\\muska\\AppData\\Local\\Temp\\ipykernel_3916\\1037050491.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  variant_data['Pathogenic_Prob'] = pathogenic_probs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Define Model (same as earlier)\n",
    "# ------------------------------------------------------------\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, dropout=0.3):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(self.fc(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class StructuralGNN(nn.Module):\n",
    "    def __init__(self, node_in_dim=128, embedding_dim=128, dropout=0.3):\n",
    "        super(StructuralGNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(node_in_dim, embedding_dim)\n",
    "        self.fc2 = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, features, adj):\n",
    "        h = torch.matmul(adj, features)\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = self.dropout(torch.matmul(adj, h))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return h.mean(dim=0)\n",
    "\n",
    "\n",
    "class SequenceTransformer(nn.Module):\n",
    "    def __init__(self, seq_len=100, embed_dim=128, num_heads=4, num_layers=2, dropout=0.3):\n",
    "        super(SequenceTransformer, self).__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_len, embed_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, seq_embeddings, variant_pos=None):\n",
    "        x = seq_embeddings + self.pos_embedding[:, : seq_embeddings.size(1), :]\n",
    "        x = self.transformer(x)\n",
    "        if variant_pos is not None:\n",
    "            seq_len = x.size(1)\n",
    "            variant_pos = torch.clamp(variant_pos, max=seq_len - 1)\n",
    "            idx = variant_pos.long().unsqueeze(-1).unsqueeze(-1).expand(-1, 1, x.size(-1))\n",
    "            variant_emb = torch.gather(x, 1, idx).squeeze(1)\n",
    "        else:\n",
    "            variant_emb = x.mean(dim=1)\n",
    "        return self.dropout(variant_emb)\n",
    "\n",
    "\n",
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self, seq_len=100, embed_dim=128, num_classes=2, dropout=0.3):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "        self.cnn_module = StructuralCNN(embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.gnn_module = StructuralGNN(node_in_dim=embed_dim, embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.seq_module = SequenceTransformer(seq_len=seq_len, embed_dim=embed_dim, dropout=dropout)\n",
    "        self.fc_final = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, contact_matrix, adj, seq_embeddings, variant_pos):\n",
    "        cnn_out = self.cnn_module(contact_matrix)                       # [1,128]\n",
    "        gnn_out = self.gnn_module(cnn_out.repeat(adj.size(0), 1), adj)  # [128]\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)           # [1,128]\n",
    "        combined = torch.cat([cnn_out.squeeze(0), gnn_out, seq_out.squeeze(0)], dim=-1)\n",
    "        output = self.fc_final(combined.unsqueeze(0))\n",
    "        return output\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load Variant Dataset\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(\"E:/vit/ai/data/BDNF_missense_expanded_mapped.csv\")\n",
    "variant_data = df[['Residue', 'Orig_AA', 'New_AA', 'Region', 'Protein change']]\n",
    "print(\"Loaded variants:\", len(variant_data))\n",
    "\n",
    "# Encode residue positions (dummy for now)\n",
    "residues = torch.tensor(variant_data['Residue'].fillna(0).values, dtype=torch.long)\n",
    "num_variants = len(variant_data)\n",
    "\n",
    "# Dummy embeddings\n",
    "contact_matrices = torch.randn(num_variants, 1, 64, 64)\n",
    "sequence_embeddings = torch.randn(num_variants, 100, 128)\n",
    "variant_positions = residues % 100\n",
    "adj = torch.eye(50)  # simple adjacency for all variants\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load or Initialize Model\n",
    "# ------------------------------------------------------------\n",
    "model = HybridVariantPredictor(seq_len=100, embed_dim=128, num_classes=2)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\", map_location=torch.device('cpu')))\n",
    "    print(\" Loaded pretrained weights from 'best_model.pth'\")\n",
    "except FileNotFoundError:\n",
    "    print(\" No pretrained model found  using untrained model weights.\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Run Predictions\n",
    "# ------------------------------------------------------------\n",
    "pred_classes, pathogenic_probs = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_variants):\n",
    "        cm = contact_matrices[i].unsqueeze(0)\n",
    "        seq = sequence_embeddings[i].unsqueeze(0)\n",
    "        vp = variant_positions[i].unsqueeze(0)\n",
    "        output = model(cm, adj, seq, vp)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        pred_classes.append(preds.item())\n",
    "        pathogenic_probs.append(probs[:, 1].item())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Save annotated results\n",
    "# ------------------------------------------------------------\n",
    "variant_data['Predicted_Class'] = pred_classes\n",
    "variant_data['Pathogenic_Prob'] = pathogenic_probs\n",
    "\n",
    "variant_data.to_csv(\"E:/vit/ai/data/BDNF_processed_with_predictions.csv\", index=False)\n",
    "print(\"\\n Predictions saved to 'BDNF_processed_with_predictions.csv'\")\n",
    "print(variant_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b82e5ef-9f6a-42fd-a640-4fd1349ff265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\muska\\anaconda3\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\muska\\anaconda3\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\muska\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\muska\\anaconda3\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\muska\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\muska\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.10.5)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.0 MB 1.3 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 0.8/12.0 MB 1.3 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.0/12.0 MB 1.3 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.3/12.0 MB 1.3 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.6/12.0 MB 1.3 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.8/12.0 MB 1.3 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 2.1/12.0 MB 1.3 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 2.4/12.0 MB 1.3 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 2.6/12.0 MB 1.3 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.9/12.0 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 3.1/12.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.4/12.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.7/12.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.9/12.0 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 4.2/12.0 MB 1.3 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 4.5/12.0 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.7/12.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 5.0/12.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 5.2/12.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.5/12.0 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.8/12.0 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 6.0/12.0 MB 1.3 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 6.0/12.0 MB 1.3 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 6.6/12.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.8/12.0 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 7.1/12.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 7.3/12.0 MB 1.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.6/12.0 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.9/12.0 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 8.1/12.0 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 8.4/12.0 MB 1.3 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 8.7/12.0 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.9/12.0 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 9.4/12.0 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 9.7/12.0 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.0/12.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.2/12.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 10.5/12.0 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.7/12.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.3/12.0 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.8/12.0 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 262.1/566.1 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 262.1/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.7 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.0/2.7 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.3/2.7 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.8/2.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.1/2.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.6/2.7 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 1.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [huggingface-hub]\n",
      "   ---------- ----------------------------- 1/4 [huggingface-hub]\n",
      "   ---------- ----------------------------- 1/4 [huggingface-hub]\n",
      "   ---------- ----------------------------- 1/4 [huggingface-hub]\n",
      "   ---------- ----------------------------- 1/4 [huggingface-hub]\n",
      "   ---------- ----------------------------- 1/4 [huggingface-hub]\n",
      "   -------------------- ------------------- 2/4 [tokenizers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ------------------------------ --------- 3/4 [transformers]\n",
      "   ---------------------------------------- 4/4 [transformers]\n",
      "\n",
      "Successfully installed huggingface-hub-0.36.0 safetensors-0.6.2 tokenizers-0.22.1 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d583800-76c2-4871-858e-1ae757e87d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc87bfe05714628b5d107f5183265c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muska\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\muska\\.cache\\huggingface\\hub\\models--facebook--esm2_t6_8M_UR50D. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e45e0147b7e40768016594b225c9e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/93.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afacff85260c46e48b806ac09c5ae5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601ec87798bd4f808d592006445aad33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/775 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c96a1eec92413daac1836f76a50c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/31.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence embedding shape: torch.Size([85, 320])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load pretrained protein language model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "model = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "# Example: BDNF protein sequence (UniProt ID: P23560)\n",
    "bdnf_seq = (\n",
    "    \"MTSRTPAAPAAGPVLPAVPLPLLRLPLLPPLHPAAAEPLHPADWDAAPAAPASPLEPAPAPAARPR\"\n",
    "    \"RSHPHFLAENTRVL...\"\n",
    ")  # use full sequence for actual embedding\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(bdnf_seq, return_tensors=\"pt\")\n",
    "\n",
    "# Generate embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    sequence_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    print(\"Sequence embedding shape:\", sequence_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7be13cf-7e3b-4c7c-8521-7b411a051ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contact matrix shape: torch.Size([1, 247, 247])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "def get_contact_map(pdb_path, threshold=8.0):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"BDNF\", pdb_path)\n",
    "    residues = [res for res in structure.get_residues() if 'CA' in res]\n",
    "    n = len(residues)\n",
    "    dist_matrix = np.zeros((n, n))\n",
    "    for i, res1 in enumerate(residues):\n",
    "        for j, res2 in enumerate(residues):\n",
    "            dist = res1['CA'] - res2['CA']\n",
    "            dist_matrix[i, j] = dist\n",
    "    contact_map = (dist_matrix < threshold).astype(float)\n",
    "    return torch.tensor(contact_map, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "contact_matrix = get_contact_map(\"E:/vit/ai/data/AF-P23560-F1-model_v6.pdb\")\n",
    "print(\"Contact matrix shape:\", contact_matrix.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f81662-8bbd-4213-b154-fefd05272886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
