{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba79569-8fb6-4370-91fa-5a719d3b7519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structural Embedding Vector Shape: torch.Size([1, 128])\n",
      "Example Embedding (first 10 values): tensor([ 0.0521, -0.0629, -0.1503, -0.0279,  0.0409,  0.0786, -0.0517,  0.0373,\n",
      "         0.0544,  0.0284], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ------------------------------\n",
    "# CNN Module (Structural Patterns)\n",
    "# ------------------------------\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self, input_channels=1, embedding_dim=128):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Input: 2D distance/contact matrix from AlphaFold (e.g., 64x64)\n",
    "        Output: Embedding vector representing structural context\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))  # global average pooling\n",
    "\n",
    "        self.fc = nn.Linear(128, embedding_dim)  # final embedding vector\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 1, H, W]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.global_pool(x)  # shape → [batch, 128, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # shape → [batch, 128]\n",
    "\n",
    "        embedding = self.fc(x)\n",
    "        return embedding\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Example usage\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulate AlphaFold contact matrix (batch_size=1, 64x64)\n",
    "    contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "\n",
    "    model = StructuralCNN(input_channels=1, embedding_dim=128)\n",
    "    embedding = model(contact_matrix)\n",
    "\n",
    "    print(\"Structural Embedding Vector Shape:\", embedding.shape)\n",
    "    print(\"Example Embedding (first 10 values):\", embedding[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79735081-34eb-4fb0-b1f7-1d5be1ca85f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33a09096-5e2c-480a-af29-b7c682d81fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyTorch Geometric is ready to use!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "print(\"✅ PyTorch Geometric is ready to use!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3f89dff-a6be-4b17-b3e8-363a61aff304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "# ------------------------------\n",
    "# GNN Module (Graph Representation)\n",
    "# ------------------------------\n",
    "class StructuralGNN(nn.Module):\n",
    "    def __init__(self, node_in_dim=128, hidden_dim=128, embedding_dim=128):\n",
    "        super(StructuralGNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Input: Graph representation of protein (nodes = residues)\n",
    "        Output: Graph-level embedding (structural + relational context)\n",
    "        \"\"\"\n",
    "        self.conv1 = GCNConv(node_in_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        \"\"\"\n",
    "        x: [num_nodes, node_in_dim] node features (from CNN or sequence embedding)\n",
    "        edge_index: [2, num_edges] connectivity between nodes\n",
    "        batch: [num_nodes] batch vector to group nodes per protein\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "\n",
    "        # Graph-level pooling (mean over all node embeddings)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046946b-e563-43fd-a691-2c6d135776d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8b440be-dbb3-42e8-b825-909e8c7beba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ------------------------------\n",
    "# Transformer Module (Sequence Context)\n",
    "# ------------------------------\n",
    "class SequenceTransformer(nn.Module):\n",
    "    def __init__(self, seq_len=512, embed_dim=128, num_heads=8, num_layers=2, dropout=0.1):\n",
    "        super(SequenceTransformer, self).__init__()\n",
    "        \"\"\"\n",
    "        Input: Sequence embeddings + positional encoding (variant position)\n",
    "        Output: Embedding vector representing sequence context\n",
    "        \"\"\"\n",
    "\n",
    "        # Positional encoding (learnable)\n",
    "        self.pos_embedding = nn.Embedding(seq_len, embed_dim)\n",
    "\n",
    "        # Transformer Encoder layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dim_feedforward=256,\n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Final sequence embedding projection\n",
    "        self.fc = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, seq_embeddings, variant_pos=None):\n",
    "        \"\"\"\n",
    "        seq_embeddings: [batch, seq_len, embed_dim]\n",
    "        variant_pos: list/tensor of variant positions (optional)\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len, _ = seq_embeddings.size()\n",
    "\n",
    "        # Add positional encoding\n",
    "        positions = torch.arange(seq_len, device=seq_embeddings.device).unsqueeze(0)\n",
    "        pos_emb = self.pos_embedding(positions)\n",
    "        x = seq_embeddings + pos_emb\n",
    "\n",
    "        # Pass through Transformer Encoder\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        # If variant position provided, extract its context vector\n",
    "        if variant_pos is not None:\n",
    "            idx = variant_pos.long().unsqueeze(-1).unsqueeze(-1).expand(-1, 1, x.size(-1))\n",
    "            variant_emb = torch.gather(x, 1, idx).squeeze(1)\n",
    "        else:\n",
    "            # Global average pooling if variant position not given\n",
    "            variant_emb = x.mean(dim=1)\n",
    "\n",
    "        out = self.fc(variant_emb)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbc67930-f40f-48a5-89b0-13294914fccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN Structural Embedding Shape: torch.Size([1, 128])\n",
      "Graph-level Embedding: tensor([[-1.1701e-01,  3.3949e-01,  3.3200e-01, -1.6349e-02, -1.1113e-01,\n",
      "          9.5515e-02, -7.8390e-03, -1.7458e-01, -1.3772e-01, -2.2421e-01,\n",
      "          2.0224e-01, -9.4489e-02,  1.9384e-01,  7.5994e-02, -1.8465e-01,\n",
      "          9.4791e-03, -1.1883e-01, -1.2106e-01,  2.1763e-05,  1.1804e-01,\n",
      "          3.4863e-01,  1.5225e-01,  1.4202e-02, -2.3250e-01, -2.8812e-01,\n",
      "         -1.8030e-01,  1.6206e-01,  1.3166e-01,  4.6108e-02, -1.8608e-01,\n",
      "          1.1743e-01,  1.1736e-01,  7.7772e-02,  1.6215e-01, -9.7333e-03,\n",
      "          1.2260e-01, -2.3181e-02, -1.1576e-01,  8.9787e-02,  4.4712e-02,\n",
      "          3.4639e-02,  1.0141e-01,  9.3240e-02,  8.5480e-02, -1.2755e-01,\n",
      "          1.9587e-01, -1.1118e-01, -3.3523e-01, -2.0722e-02,  2.6581e-01,\n",
      "         -8.5945e-02,  1.1450e-01,  6.3505e-02,  1.3858e-01, -2.1607e-02,\n",
      "          2.5020e-01,  4.5125e-02,  7.5419e-02, -4.7158e-02, -1.0258e-01,\n",
      "          9.9375e-02,  1.0669e-02,  1.8400e-02, -1.5782e-01, -2.4949e-01,\n",
      "          1.9381e-01, -9.1626e-02,  3.1171e-02, -8.0224e-02, -3.4865e-01,\n",
      "         -1.2390e-01,  1.0123e-01,  2.5883e-02, -9.5285e-02,  8.0538e-02,\n",
      "          1.0247e-01, -4.8129e-02,  1.2760e-01,  5.8030e-02,  3.7147e-02,\n",
      "          2.5259e-01, -1.7235e-01, -1.6056e-01,  8.9492e-02, -6.3089e-02,\n",
      "         -7.1649e-04,  1.5363e-01,  6.0753e-02, -8.1248e-02, -1.8657e-02,\n",
      "         -6.6180e-02, -2.1729e-01,  8.4931e-02,  6.7349e-02,  1.4076e-01,\n",
      "          2.1226e-01,  7.9398e-02, -1.0427e-01,  8.8170e-02,  1.2009e-02,\n",
      "         -1.6195e-01, -2.2343e-01, -1.0038e-01,  2.5526e-02,  1.5023e-01,\n",
      "         -2.8270e-02, -1.2960e-01,  2.6706e-01,  3.4674e-01, -4.1062e-02,\n",
      "         -8.2633e-02,  9.2871e-02, -9.8129e-02, -7.9218e-02, -5.7825e-02,\n",
      "         -8.6368e-02,  5.6217e-02, -1.2386e-01, -8.0169e-02,  2.7275e-01,\n",
      "          1.8650e-02, -5.8019e-02, -1.2783e-01,  2.8358e-02, -2.6659e-02,\n",
      "         -1.5722e-01, -8.3620e-02, -4.3669e-03]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Assume from previous CNN code:\n",
    "# cnn_model = StructuralCNN()\n",
    "# contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "cnn_embedding = cnn_model(contact_matrix)  # shape: [1, 128]\n",
    "\n",
    "# Suppose each residue is represented by CNN embedding\n",
    "# For simplicity, simulate 50 residues → 50 nodes, each 128-dim feature\n",
    "num_residues = 50\n",
    "x = torch.rand(num_residues, 128)\n",
    "\n",
    "# Define dummy edges (simple chain or contact-based)\n",
    "edge_index = torch.tensor([\n",
    "    [i for i in range(num_residues - 1)] + [i + 1 for i in range(num_residues - 1)],\n",
    "    [i + 1 for i in range(num_residues - 1)] + [i for i in range(num_residues - 1)]\n",
    "], dtype=torch.long)\n",
    "\n",
    "# Batch info (1 graph → all nodes belong to same protein)\n",
    "batch = torch.zeros(num_residues, dtype=torch.long)\n",
    "\n",
    "# Run GNN\n",
    "gnn_model = StructuralGNN(node_in_dim=128)\n",
    "gnn_embedding = gnn_model(x, edge_index, batch)\n",
    "\n",
    "print(\"GNN Structural Embedding Shape:\", gnn_embedding.shape)\n",
    "print(\"Graph-level Embedding:\", gnn_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41030067-c8e2-4bef-9533-9a61a167efd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN embedding shape: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ------------------------------\n",
    "# CNN Module (Structural Patterns)\n",
    "# ------------------------------\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, 128)  # assuming input 64×64\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize CNN model\n",
    "cnn_model = StructuralCNN()\n",
    "\n",
    "# Example input (64×64 contact matrix)\n",
    "contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "\n",
    "# Get CNN embedding\n",
    "cnn_embedding = cnn_model(contact_matrix)\n",
    "print(\"CNN embedding shape:\", cnn_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f627ade6-dd02-491f-affc-fdf069b42771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Context Embedding Shape: torch.Size([1, 128])\n"
     ]
    }
   ],
   "source": [
    "# Simulated amino acid sequence embeddings (batch=1, seq_len=100, embed_dim=128)\n",
    "seq_embeddings = torch.rand(1, 100, 128)\n",
    "\n",
    "# Variant at position 45\n",
    "variant_position = torch.tensor([45])\n",
    "\n",
    "model = SequenceTransformer(seq_len=100, embed_dim=128)\n",
    "seq_context_emb = model(seq_embeddings, variant_position)\n",
    "\n",
    "print(\"Sequence Context Embedding Shape:\", seq_context_emb.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af452728-ea7a-43d7-9285-166f1b426e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assume you already defined:\n",
    "# - StructuralCNN\n",
    "# - StructuralGNN\n",
    "# - SequenceTransformer\n",
    "\n",
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self, seq_len=512, embed_dim=128, num_classes=2):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "\n",
    "        # --- Individual Modules ---\n",
    "        self.cnn_module = StructuralCNN(input_channels=1, embedding_dim=embed_dim)\n",
    "        self.gnn_module = StructuralGNN(node_in_dim=embed_dim, hidden_dim=128, embedding_dim=embed_dim)\n",
    "        self.seq_module = SequenceTransformer(seq_len=seq_len, embed_dim=embed_dim)\n",
    "\n",
    "        # --- Fusion Layer ---\n",
    "        self.fc_fusion = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 3, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # --- Output Prediction Head ---\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, contact_matrix, residue_graph, seq_embeddings, variant_pos=None):\n",
    "        \"\"\"\n",
    "        contact_matrix: [B, 1, H, W]   -> CNN\n",
    "        residue_graph: tuple(x, edge_index, batch) -> GNN\n",
    "        seq_embeddings: [B, seq_len, embed_dim]    -> Transformer\n",
    "        \"\"\"\n",
    "\n",
    "        # CNN output → local structure\n",
    "        cnn_out = self.cnn_module(contact_matrix)\n",
    "\n",
    "        # GNN output → global structure\n",
    "        x, edge_index, batch = residue_graph\n",
    "        gnn_out = self.gnn_module(x, edge_index, batch)\n",
    "\n",
    "        # Transformer output → sequence context\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)\n",
    "\n",
    "        # Combine embeddings (concatenate)\n",
    "        combined = torch.cat([cnn_out, gnn_out, seq_out], dim=-1)\n",
    "\n",
    "        # Fusion and classification\n",
    "        fused = self.fc_fusion(combined)\n",
    "        logits = self.classifier(fused)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aeaf40b7-5a39-4c19-b405-b1211aa2a94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0067, 0.0694]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self, input_channels=1, embedding_dim=128):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Input: 2D contact/distance matrix (AlphaFold)\n",
    "        Output: Embedding vector representing structural context\n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        self.fc = nn.Linear(128, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.global_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "model = HybridVariantPredictor(seq_len=100, embed_dim=128, num_classes=2)\n",
    "output = model(contact_matrix, residue_graph, seq_embeddings, variant_pos)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7524efec-1952-4926-9d3c-29adeb50393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] - Loss: 0.6879 - Accuracy: 0.5000\n",
      "Epoch [2/5] - Loss: 0.6833 - Accuracy: 0.7500\n",
      "Epoch [3/5] - Loss: 0.6741 - Accuracy: 1.0000\n",
      "Epoch [4/5] - Loss: 0.6632 - Accuracy: 1.0000\n",
      "Epoch [5/5] - Loss: 0.6487 - Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Initialize model\n",
    "model = HybridVariantPredictor(seq_len=100, embed_dim=128, num_classes=2)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()       # good for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "# Example: simulate a batch of 4 samples\n",
    "batch_size = 4\n",
    "\n",
    "contact_matrices = torch.rand(batch_size, 1, 64, 64)\n",
    "num_residues = 50\n",
    "seq_len = 100\n",
    "variant_positions = torch.randint(0, seq_len, (batch_size,))\n",
    "\n",
    "# Each sample → different graph\n",
    "x = torch.rand(num_residues * batch_size, 128)\n",
    "edge_index = torch.tensor([\n",
    "    [i for i in range(num_residues - 1)] * batch_size + [i + 1 for i in range(num_residues - 1)] * batch_size,\n",
    "    [i + 1 for i in range(num_residues - 1)] * batch_size + [i for i in range(num_residues - 1)] * batch_size\n",
    "], dtype=torch.long)\n",
    "batch = torch.repeat_interleave(torch.arange(batch_size), num_residues)\n",
    "\n",
    "residue_graph = (x, edge_index, batch)\n",
    "\n",
    "seq_embeddings = torch.rand(batch_size, seq_len, 128)\n",
    "labels = torch.randint(0, 2, (batch_size,))  # 0=benign, 1=pathogenic\n",
    "epochs = 5  # increase later\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(contact_matrices, residue_graph, seq_embeddings, variant_positions)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Accuracy\n",
    "    preds = torch.argmax(outputs, dim=1)\n",
    "    acc = (preds == labels).float().mean()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {loss.item():.4f} - Accuracy: {acc.item():.4f}\")\n",
    "torch.save(model.state_dict(), \"hybrid_variant_predictor.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3765e58-a5b5-45aa-8344-052d6d1bde2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       Name       Gene(s)  \\\n",
      "0  NM_001709.5(BDNF):c.715T>G (p.Cys239Gly)  BDNF|BDNF-AS   \n",
      "1  NM_001709.5(BDNF):c.715T>G (p.Cys239Gly)  BDNF|BDNF-AS   \n",
      "2  NM_001709.5(BDNF):c.715T>G (p.Cys239Gly)  BDNF|BDNF-AS   \n",
      "3  NM_001709.5(BDNF):c.715T>G (p.Cys239Gly)  BDNF|BDNF-AS   \n",
      "4  NM_001709.5(BDNF):c.715T>G (p.Cys239Gly)  BDNF|BDNF-AS   \n",
      "\n",
      "                      Protein change           Condition(s)     Accession  \\\n",
      "0  C239G, C247G, C254G, C268G, C321G  BDNF-related disorder  VCV003344608   \n",
      "1  C239G, C247G, C254G, C268G, C321G  BDNF-related disorder  VCV003344608   \n",
      "2  C239G, C247G, C254G, C268G, C321G  BDNF-related disorder  VCV003344608   \n",
      "3  C239G, C247G, C254G, C268G, C321G  BDNF-related disorder  VCV003344608   \n",
      "4  C239G, C247G, C254G, C268G, C321G  BDNF-related disorder  VCV003344608   \n",
      "\n",
      "   GRCh37Chromosome  GRCh37Location  GRCh38Chromosome  GRCh38Location  \\\n",
      "0                11        27679397                11        27657850   \n",
      "1                11        27679397                11        27657850   \n",
      "2                11        27679397                11        27657850   \n",
      "3                11        27679397                11        27657850   \n",
      "4                11        27679397                11        27657850   \n",
      "\n",
      "   VariationID  ...  Oncogenicity review status VariantType Orig_AA Residue  \\\n",
      "0      3344608  ...                         NaN    missense       C   239.0   \n",
      "1      3344608  ...                         NaN    missense       C   247.0   \n",
      "2      3344608  ...                         NaN    missense       C   254.0   \n",
      "3      3344608  ...                         NaN    missense       C   268.0   \n",
      "4      3344608  ...                         NaN    missense       C   321.0   \n",
      "\n",
      "  New_AA                                             Parsed        Region  \\\n",
      "0      G  [('C', '239', 'G'), ('C', '247', 'G'), ('C', '...        mature   \n",
      "1      G  [('C', '239', 'G'), ('C', '247', 'G'), ('C', '...        mature   \n",
      "2      G  [('C', '239', 'G'), ('C', '247', 'G'), ('C', '...  out_of_range   \n",
      "3      G  [('C', '239', 'G'), ('C', '247', 'G'), ('C', '...  out_of_range   \n",
      "4      G  [('C', '239', 'G'), ('C', '247', 'G'), ('C', '...  out_of_range   \n",
      "\n",
      "  Mature_pos         Mapping  Truncation_length  \n",
      "0      111.0           C239G                NaN  \n",
      "1      119.0  Mismatch(R->C)                NaN  \n",
      "2        NaN    Out_of_range                NaN  \n",
      "3        NaN    Out_of_range                NaN  \n",
      "4        NaN    Out_of_range                NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Index(['Name', 'Gene(s)', 'Protein change', 'Condition(s)', 'Accession',\n",
      "       'GRCh37Chromosome', 'GRCh37Location', 'GRCh38Chromosome',\n",
      "       'GRCh38Location', 'VariationID', 'AlleleID(s)', 'dbSNP ID',\n",
      "       'Canonical SPDI', 'Variant type', 'Molecular consequence',\n",
      "       'Germline classification', 'Germline date last evaluated',\n",
      "       'Germline review status', 'Somatic clinical impact',\n",
      "       'Somatic clinical impact date last evaluated',\n",
      "       'Somatic clinical impact review status', 'Oncogenicity classification',\n",
      "       'Oncogenicity date last evaluated', 'Oncogenicity review status',\n",
      "       'VariantType', 'Orig_AA', 'Residue', 'New_AA', 'Parsed', 'Region',\n",
      "       'Mature_pos', 'Mapping', 'Truncation_length'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file (replace the filename with your actual one)\n",
    "df = pd.read_csv(\"E:/vit/ai/data/BDNF_missense_expanded_mapped.csv\")\n",
    "\n",
    "# Preview dataset\n",
    "print(df.head())\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5595afd3-ac6e-41dc-a68f-f7f9f7653765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 21 valid variants for modeling.\n",
      "    Residue Orig_AA New_AA  label\n",
      "30      186       C      Y      1\n",
      "31      194       C      Y      1\n",
      "32      201       C      Y      1\n",
      "33      215       C      Y      1\n",
      "34      268       C      Y      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"E:/vit/ai/data/BDNF_missense_expanded_mapped.csv\")\n",
    "\n",
    "# Step 1: Filter missense variants\n",
    "df = df[df[\"VariantType\"].str.lower() == \"missense\"].copy()\n",
    "\n",
    "# Step 2: Drop rows without residue positions or labels\n",
    "df = df.dropna(subset=[\"Residue\"])\n",
    "\n",
    "# Step 3: Convert residue positions to integers\n",
    "df[\"Residue\"] = df[\"Residue\"].astype(int)\n",
    "\n",
    "# Step 4: Encode labels\n",
    "# Try to use 'Germline classification' or 'Oncogenicity classification' if available\n",
    "if \"Germline classification\" in df.columns:\n",
    "    label_col = \"Germline classification\"\n",
    "elif \"Oncogenicity classification\" in df.columns:\n",
    "    label_col = \"Oncogenicity classification\"\n",
    "else:\n",
    "    raise ValueError(\"No pathogenicity label found in CSV\")\n",
    "\n",
    "# Simplify to binary labels\n",
    "def encode_label(val):\n",
    "    if isinstance(val, str):\n",
    "        val = val.lower()\n",
    "        if \"pathogenic\" in val:\n",
    "            return 1\n",
    "        elif \"benign\" in val:\n",
    "            return 0\n",
    "    return None\n",
    "\n",
    "df[\"label\"] = df[label_col].apply(encode_label)\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "df[\"label\"] = df[\"label\"].astype(int)\n",
    "\n",
    "print(f\"✅ Processed {len(df)} valid variants for modeling.\")\n",
    "print(df[[\"Residue\", \"Orig_AA\", \"New_AA\", \"label\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a06203e7-89a7-4b3c-b25a-49503b6d98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model output: tensor([[0.5051]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "\n",
    "# ------------------------------\n",
    "# 1. CNN Module (Structural Patterns)\n",
    "# ------------------------------\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, 128)  # for input 64x64\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x  # [batch, 128]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Simplified GNN (Manual message passing)\n",
    "# ------------------------------\n",
    "class SimpleGNN(nn.Module):\n",
    "    def __init__(self, in_features=128, hidden_dim=64, out_features=64):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_features)\n",
    "\n",
    "    def forward(self, features, adj):\n",
    "        h = torch.matmul(adj, features)  # aggregate neighbors\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = torch.matmul(adj, h)\n",
    "        h = self.fc2(h)\n",
    "        return h.mean(dim=0)  # global mean pooling [64]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Transformer (Sequence Context)\n",
    "# ------------------------------\n",
    "class SequenceTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=128, nhead=4, hidden_dim=256, num_layers=2):\n",
    "        super(SequenceTransformer, self).__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim, nhead=nhead, dim_feedforward=hidden_dim, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, seq_embeddings, variant_pos=None):\n",
    "        x = self.transformer(seq_embeddings)  # [batch, seq_len, embed_dim]\n",
    "        if variant_pos is not None:\n",
    "            seq_len = x.size(1)\n",
    "            variant_pos = torch.clamp(variant_pos, max=seq_len - 1)\n",
    "            idx = variant_pos.long().unsqueeze(-1).unsqueeze(-1).expand(-1, 1, x.size(-1))\n",
    "            variant_emb = torch.gather(x, 1, idx).squeeze(1)\n",
    "        else:\n",
    "            variant_emb = x.mean(dim=1)\n",
    "        return variant_emb  # [batch, embed_dim]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Hybrid Model (CNN + GNN + Transformer)\n",
    "# ------------------------------\n",
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "        self.cnn_module = StructuralCNN()\n",
    "        self.gnn_module = SimpleGNN()\n",
    "        self.seq_module = SequenceTransformer(input_dim=128)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 64 + 128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, contact_matrix, adj, seq_embeddings, variant_pos):\n",
    "        cnn_out = self.cnn_module(contact_matrix)       # [1,128]\n",
    "        node_features = cnn_out.repeat(adj.size(0), 1)  # replicate to [num_nodes,128]\n",
    "        gnn_out = self.gnn_module(node_features, adj)   # [64]\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)  # [1,128]\n",
    "        combined = torch.cat([cnn_out.squeeze(0), gnn_out, seq_out.squeeze(0)], dim=-1)\n",
    "        return self.classifier(combined.unsqueeze(0))   # [1,1]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Test Run with Dummy Data\n",
    "# ------------------------------\n",
    "contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "num_nodes = 50\n",
    "G = nx.erdos_renyi_graph(num_nodes, 0.1)\n",
    "adj = torch.tensor(nx.to_numpy_array(G), dtype=torch.float32)\n",
    "seq_embeddings = torch.rand(1, 100, 128)\n",
    "variant_pos = torch.tensor([186])  # intentionally out of bounds\n",
    "\n",
    "# Initialize model\n",
    "model = HybridVariantPredictor()\n",
    "output = model(contact_matrix, adj, seq_embeddings, variant_pos)\n",
    "print(\"✅ Model output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e85efbe-db16-4377-b1ee-101ce04ef600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model output: tensor([[0.5054]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "\n",
    "# ------------------------------\n",
    "# 1. CNN Module (Structural Patterns)\n",
    "# ------------------------------\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, 128)  # for input 64x64\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x  # [batch, 128]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Simplified GNN (Manual message passing)\n",
    "# ------------------------------\n",
    "class SimpleGNN(nn.Module):\n",
    "    def __init__(self, in_features=128, hidden_dim=64, out_features=64):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, out_features)\n",
    "\n",
    "    def forward(self, features, adj):\n",
    "        h = torch.matmul(adj, features)  # aggregate neighbors\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = torch.matmul(adj, h)\n",
    "        h = self.fc2(h)\n",
    "        return h.mean(dim=0)  # global mean pooling [64]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Transformer (Sequence Context)\n",
    "# ------------------------------\n",
    "class SequenceTransformer(nn.Module):\n",
    "    def __init__(self, input_dim=128, nhead=4, hidden_dim=256, num_layers=2):\n",
    "        super(SequenceTransformer, self).__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=input_dim, nhead=nhead, dim_feedforward=hidden_dim, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, seq_embeddings, variant_pos=None):\n",
    "        x = self.transformer(seq_embeddings)  # [batch, seq_len, embed_dim]\n",
    "        if variant_pos is not None:\n",
    "            seq_len = x.size(1)\n",
    "            variant_pos = torch.clamp(variant_pos, max=seq_len - 1)\n",
    "            idx = variant_pos.long().unsqueeze(-1).unsqueeze(-1).expand(-1, 1, x.size(-1))\n",
    "            variant_emb = torch.gather(x, 1, idx).squeeze(1)\n",
    "        else:\n",
    "            variant_emb = x.mean(dim=1)\n",
    "        return variant_emb  # [batch, embed_dim]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Hybrid Model (CNN + GNN + Transformer)\n",
    "# ------------------------------\n",
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "        self.cnn_module = StructuralCNN()\n",
    "        self.gnn_module = SimpleGNN()\n",
    "        self.seq_module = SequenceTransformer(input_dim=128)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 + 64 + 128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, contact_matrix, adj, seq_embeddings, variant_pos):\n",
    "        cnn_out = self.cnn_module(contact_matrix)       # [1,128]\n",
    "        node_features = cnn_out.repeat(adj.size(0), 1)  # replicate for nodes [num_nodes,128]\n",
    "        gnn_out = self.gnn_module(node_features, adj)   # [64]\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)  # [1,128]\n",
    "        combined = torch.cat([cnn_out.squeeze(0), gnn_out, seq_out.squeeze(0)], dim=-1)\n",
    "        return self.classifier(combined.unsqueeze(0))   # [1,1]\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Test Run with Dummy Data\n",
    "# ------------------------------\n",
    "contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "num_nodes = 50\n",
    "G = nx.erdos_renyi_graph(num_nodes, 0.1)\n",
    "adj = torch.tensor(nx.to_numpy_array(G), dtype=torch.float32)\n",
    "seq_embeddings = torch.rand(1, 100, 128)\n",
    "variant_pos = torch.tensor([186])  # intentionally out of bounds\n",
    "\n",
    "# Initialize model\n",
    "model = HybridVariantPredictor()\n",
    "output = model(contact_matrix, adj, seq_embeddings, variant_pos)\n",
    "print(\"✅ Model output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "07fcb6cc-3c75-42d8-8694-0ecdf62d31ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self, seq_len=100, embed_dim=128, num_classes=2, dropout=0.3):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "        self.cnn_module = StructuralCNN(embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.gnn_module = StructuralGNN(node_in_dim=embed_dim, embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.seq_module = SequenceTransformer(seq_len=seq_len, embed_dim=embed_dim, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(embed_dim * 3, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, contact_matrix, residue_graph, seq_embeddings, variant_pos):\n",
    "        cnn_out = self.cnn_module(contact_matrix)\n",
    "        gnn_out = self.gnn_module(residue_graph)\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)\n",
    "\n",
    "        combined = torch.cat((cnn_out, gnn_out, seq_out), dim=1)\n",
    "        x = F.relu(self.bn1(self.fc1(combined)))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=1e-4, \n",
    "    weight_decay=1e-5  # ← L2 regularization\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d84a6a63-a7e7-4bcd-98e5-7a185f732934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model output shape: torch.Size([2])\n",
      "✅ Output: tensor([-0.0141,  0.0672], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# =========================\n",
    "# 1. CNN Module\n",
    "# =========================\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, dropout=0.3):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(self.fc(x))\n",
    "        return x  # [batch, embedding_dim]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. GNN Module (Matrix-based)\n",
    "# =========================\n",
    "class StructuralGNN(nn.Module):\n",
    "    def __init__(self, node_in_dim=128, embedding_dim=128, dropout=0.3):\n",
    "        super(StructuralGNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(node_in_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, node_features, adj):\n",
    "        # node_features: [N, F]\n",
    "        # adj: [N, N]\n",
    "        h = torch.matmul(adj, node_features)\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = torch.matmul(adj, h)\n",
    "        h = self.dropout(F.relu(self.fc2(h)))\n",
    "        gnn_embedding = torch.mean(h, dim=0)  # graph-level embedding\n",
    "        return gnn_embedding  # [embedding_dim]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3. Transformer Module\n",
    "# =========================\n",
    "class SequenceTransformer(nn.Module):\n",
    "    def __init__(self, seq_len=100, embed_dim=128, dropout=0.3):\n",
    "        super(SequenceTransformer, self).__init__()\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_len, embed_dim))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=8, dim_feedforward=256, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        self.fc = nn.Linear(embed_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, seq_embeddings, variant_pos):\n",
    "        # seq_embeddings: [batch, seq_len, embed_dim]\n",
    "        x = seq_embeddings + self.pos_embedding\n",
    "        x = self.transformer(x)\n",
    "        variant_token = x[:, variant_pos, :]  # extract variant position embedding\n",
    "        x = self.dropout(self.fc(variant_token))\n",
    "        return x  # [batch, embed_dim]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4. Hybrid Model\n",
    "# =========================\n",
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self, seq_len=100, embed_dim=128, num_classes=2, dropout=0.3):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "        self.cnn_module = StructuralCNN(embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.gnn_module = StructuralGNN(node_in_dim=embed_dim, embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.seq_module = SequenceTransformer(seq_len=seq_len, embed_dim=embed_dim, dropout=dropout)\n",
    "\n",
    "        self.fc1 = nn.Linear(embed_dim * 3, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, contact_matrix, adj, seq_embeddings, variant_pos):\n",
    "        cnn_out = self.cnn_module(contact_matrix)  # [1, 128]\n",
    "        # For GNN, assume 50 nodes with same embedding dim as CNN output\n",
    "        node_features = torch.randn(50, cnn_out.shape[-1])\n",
    "        gnn_out = self.gnn_module(node_features, adj)  # [128]\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)  # [1, 128]\n",
    "\n",
    "        combined = torch.cat([cnn_out.squeeze(0), gnn_out, seq_out.squeeze(0)], dim=-1)\n",
    "        x = F.relu(self.fc1(combined))\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5. Example Run\n",
    "# =========================\n",
    "seq_len = 100\n",
    "embed_dim = 128\n",
    "\n",
    "contact_matrix = torch.rand(1, 1, 64, 64)\n",
    "adj = torch.eye(50)\n",
    "seq_embeddings = torch.rand(1, seq_len, embed_dim)\n",
    "variant_pos = 10\n",
    "\n",
    "model = HybridVariantPredictor(seq_len=seq_len, embed_dim=embed_dim, num_classes=2, dropout=0.3)\n",
    "output = model(contact_matrix, adj, seq_embeddings, variant_pos)\n",
    "\n",
    "print(\"✅ Model output shape:\", output.shape)\n",
    "print(\"✅ Output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96c1f345-6b99-4bcf-b237-73ba266a71b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded variants: 239\n",
      "⚠️ No pretrained model found — using untrained model weights.\n",
      "\n",
      "✅ Predictions saved to 'BDNF_processed_with_predictions.csv'\n",
      "   Residue Orig_AA New_AA        Region                     Protein change  \\\n",
      "0    239.0       C      G        mature  C239G, C247G, C254G, C268G, C321G   \n",
      "1    247.0       C      G        mature  C239G, C247G, C254G, C268G, C321G   \n",
      "2    254.0       C      G  out_of_range  C239G, C247G, C254G, C268G, C321G   \n",
      "3    268.0       C      G  out_of_range  C239G, C247G, C254G, C268G, C321G   \n",
      "4    321.0       C      G  out_of_range  C239G, C247G, C254G, C268G, C321G   \n",
      "\n",
      "   Predicted_Class  Pathogenic_Prob  \n",
      "0                1         0.508206  \n",
      "1                0         0.489482  \n",
      "2                0         0.474495  \n",
      "3                0         0.468924  \n",
      "4                0         0.479513  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muska\\AppData\\Local\\Temp\\ipykernel_3916\\1037050491.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  variant_data['Predicted_Class'] = pred_classes\n",
      "C:\\Users\\muska\\AppData\\Local\\Temp\\ipykernel_3916\\1037050491.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  variant_data['Pathogenic_Prob'] = pathogenic_probs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Define Model (same as earlier)\n",
    "# ------------------------------------------------------------\n",
    "class StructuralCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=128, dropout=0.3):\n",
    "        super(StructuralCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(32 * 16 * 16, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(self.fc(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class StructuralGNN(nn.Module):\n",
    "    def __init__(self, node_in_dim=128, embedding_dim=128, dropout=0.3):\n",
    "        super(StructuralGNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(node_in_dim, embedding_dim)\n",
    "        self.fc2 = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, features, adj):\n",
    "        h = torch.matmul(adj, features)\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = self.dropout(torch.matmul(adj, h))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return h.mean(dim=0)\n",
    "\n",
    "\n",
    "class SequenceTransformer(nn.Module):\n",
    "    def __init__(self, seq_len=100, embed_dim=128, num_heads=4, num_layers=2, dropout=0.3):\n",
    "        super(SequenceTransformer, self).__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim, nhead=num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_len, embed_dim))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, seq_embeddings, variant_pos=None):\n",
    "        x = seq_embeddings + self.pos_embedding[:, : seq_embeddings.size(1), :]\n",
    "        x = self.transformer(x)\n",
    "        if variant_pos is not None:\n",
    "            seq_len = x.size(1)\n",
    "            variant_pos = torch.clamp(variant_pos, max=seq_len - 1)\n",
    "            idx = variant_pos.long().unsqueeze(-1).unsqueeze(-1).expand(-1, 1, x.size(-1))\n",
    "            variant_emb = torch.gather(x, 1, idx).squeeze(1)\n",
    "        else:\n",
    "            variant_emb = x.mean(dim=1)\n",
    "        return self.dropout(variant_emb)\n",
    "\n",
    "\n",
    "class HybridVariantPredictor(nn.Module):\n",
    "    def __init__(self, seq_len=100, embed_dim=128, num_classes=2, dropout=0.3):\n",
    "        super(HybridVariantPredictor, self).__init__()\n",
    "        self.cnn_module = StructuralCNN(embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.gnn_module = StructuralGNN(node_in_dim=embed_dim, embedding_dim=embed_dim, dropout=dropout)\n",
    "        self.seq_module = SequenceTransformer(seq_len=seq_len, embed_dim=embed_dim, dropout=dropout)\n",
    "        self.fc_final = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, contact_matrix, adj, seq_embeddings, variant_pos):\n",
    "        cnn_out = self.cnn_module(contact_matrix)                       # [1,128]\n",
    "        gnn_out = self.gnn_module(cnn_out.repeat(adj.size(0), 1), adj)  # [128]\n",
    "        seq_out = self.seq_module(seq_embeddings, variant_pos)           # [1,128]\n",
    "        combined = torch.cat([cnn_out.squeeze(0), gnn_out, seq_out.squeeze(0)], dim=-1)\n",
    "        output = self.fc_final(combined.unsqueeze(0))\n",
    "        return output\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load Variant Dataset\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(\"E:/vit/ai/data/BDNF_missense_expanded_mapped.csv\")\n",
    "variant_data = df[['Residue', 'Orig_AA', 'New_AA', 'Region', 'Protein change']]\n",
    "print(\"Loaded variants:\", len(variant_data))\n",
    "\n",
    "# Encode residue positions (dummy for now)\n",
    "residues = torch.tensor(variant_data['Residue'].fillna(0).values, dtype=torch.long)\n",
    "num_variants = len(variant_data)\n",
    "\n",
    "# Dummy embeddings\n",
    "contact_matrices = torch.randn(num_variants, 1, 64, 64)\n",
    "sequence_embeddings = torch.randn(num_variants, 100, 128)\n",
    "variant_positions = residues % 100\n",
    "adj = torch.eye(50)  # simple adjacency for all variants\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load or Initialize Model\n",
    "# ------------------------------------------------------------\n",
    "model = HybridVariantPredictor(seq_len=100, embed_dim=128, num_classes=2)\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\", map_location=torch.device('cpu')))\n",
    "    print(\"✅ Loaded pretrained weights from 'best_model.pth'\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠️ No pretrained model found — using untrained model weights.\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Run Predictions\n",
    "# ------------------------------------------------------------\n",
    "pred_classes, pathogenic_probs = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_variants):\n",
    "        cm = contact_matrices[i].unsqueeze(0)\n",
    "        seq = sequence_embeddings[i].unsqueeze(0)\n",
    "        vp = variant_positions[i].unsqueeze(0)\n",
    "        output = model(cm, adj, seq, vp)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        pred_classes.append(preds.item())\n",
    "        pathogenic_probs.append(probs[:, 1].item())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Save annotated results\n",
    "# ------------------------------------------------------------\n",
    "variant_data['Predicted_Class'] = pred_classes\n",
    "variant_data['Pathogenic_Prob'] = pathogenic_probs\n",
    "\n",
    "variant_data.to_csv(\"E:/vit/ai/data/BDNF_processed_with_predictions.csv\", index=False)\n",
    "print(\"\\n✅ Predictions saved to 'BDNF_processed_with_predictions.csv'\")\n",
    "print(variant_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6d583800-76c2-4871-858e-1ae757e87d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc87bfe05714628b5d107f5183265c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muska\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\muska\\.cache\\huggingface\\hub\\models--facebook--esm2_t6_8M_UR50D. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e45e0147b7e40768016594b225c9e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/93.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afacff85260c46e48b806ac09c5ae5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601ec87798bd4f808d592006445aad33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/775 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c96a1eec92413daac1836f76a50c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/31.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence embedding shape: torch.Size([85, 320])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load pretrained protein language model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "model = AutoModel.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "# Example: BDNF protein sequence (UniProt ID: P23560)\n",
    "bdnf_seq = (\n",
    "    \"MTSRTPAAPAAGPVLPAVPLPLLRLPLLPPLHPAAAEPLHPADWDAAPAAPASPLEPAPAPAARPR\"\n",
    "    \"RSHPHFLAENTRVL...\"\n",
    ")  # use full sequence for actual embedding\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(bdnf_seq, return_tensors=\"pt\")\n",
    "\n",
    "# Generate embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    sequence_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    print(\"Sequence embedding shape:\", sequence_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7be13cf-7e3b-4c7c-8521-7b411a051ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contact matrix shape: torch.Size([1, 247, 247])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Bio.PDB import PDBParser\n",
    "\n",
    "def get_contact_map(pdb_path, threshold=8.0):\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"BDNF\", pdb_path)\n",
    "    residues = [res for res in structure.get_residues() if 'CA' in res]\n",
    "    n = len(residues)\n",
    "    dist_matrix = np.zeros((n, n))\n",
    "    for i, res1 in enumerate(residues):\n",
    "        for j, res2 in enumerate(residues):\n",
    "            dist = res1['CA'] - res2['CA']\n",
    "            dist_matrix[i, j] = dist\n",
    "    contact_map = (dist_matrix < threshold).astype(float)\n",
    "    return torch.tensor(contact_map, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "contact_matrix = get_contact_map(\"E:/vit/ai/data/AF-P23560-F1-model_v6.pdb\")\n",
    "print(\"Contact matrix shape:\", contact_matrix.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f81662-8bbd-4213-b154-fefd05272886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
